import os
import sys
import pickle
import json
import random
import operator
import inspect

import numpy as np
import matplotlib.pyplot as plt
import pylatex as tex
from cycler import cycler
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.ticker as plticker
from scipy.stats import pearsonr
from scipy.stats import norm as normal_dist_gen
import seaborn

from simulator.plot import Plot
import simulator.simulator_utils as s_utils

class ReportGenerator:

  _colors = ['blue',
             'green',
             'red',
             'cyan',
             'magenta',
             'yellow',
             'black',
             'green',
             'purple',
             'plum',
             'orange']

  def __init__(self, files, labels, file_prefix='rep_gen_'):
    """Creates a new `ReportGenerator` instance.

    Args:
      `files`: A list of lists s.t. each list contains a filenames
        that should be grouped together and showed by the same curve.
      `labels`: A list of strings of labels for legend.
      `file_prefix`: A prefix that will be attached to all files
        generated by this instance (plot pngs and pdfs).
    """

    if not isinstance(files, list) or not files:
      raise ValueError('`files` must be non-empty list.')

    if not isinstance(labels, list) or not labels:
      raise ValueError('`labels` must be non-empty list.')

    if any(not isinstance(f, list) for f in files):
      raise ValueError('Each element in `files` must be a list.')

    if any(not f for f in files):
      raise ValueError('There are empty list in `files`.')

    if len(labels) != len(files):
      err_msg = ("`labels` list must be of same size as "
                 "`files` list.")
      raise ValueError(err_msg)

    dirname = os.path.join(os.path.dirname(os.path.abspath(__file__)),
                          'summaries',
                          'reports')

    if not os.path.exists(dirname):
      os.makedirs(dirname)

    self._dirname = os.path.join(dirname, file_prefix)

    if not os.path.exists(self._dirname):
      os.makedirs(self._dirname)

    for f in os.listdir(self._dirname):
      if f.endswith('.pdf') or f.endswith('.tex'):
        os.remove(os.path.join(self._dirname, f))

    self._images_dirname = os.path.join(self._dirname, 'images')

    if not os.path.exists(self._images_dirname):
      os.makedirs(self._images_dirname)

    self._mses = [MultiSummaryExtractor(f) for f in files]
    self._labels = labels
    self._file_prefix = file_prefix

    max_len = len(files)

    self._linewidths = [2 for i in range(max_len)]
    self._markers = ['o' for i in range(max_len)]

    self._width = r'1\textwidth'
    self._position = 'ht'
    self._pdf_filename = os.path.join(self._dirname, self._file_prefix)
    self._fig_width = 8
    self._fig_height = 4


  def generate_report(self, custom_text=None):
    """Generates pdf file with report for multiple experiments.

    Args:
      `custom_text`: A text that will be added to the beginning of the
        pdf file.
    """
    doc = tex.Document(self._pdf_filename)
    doc.append("""Results


        """)

    self._create_specs_table(doc)

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_sep_ratio_vs_err_differ())
      plot_.add_caption('Average overfitting for min value of test error vs separation ratio.')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_sep_ratio_vs_final_err_differ())
      plot_.add_caption('Average overfitting for final value of test error vs separation ratio.')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_diffusion_vs_min_error())
      plot_.add_caption('Average min 0-1 error vs average diffusion to achieve this error.')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_n_steps_vs_min_error())
      plot_.add_caption('Average min 0-1 error vs average epochs to achieve this error.')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_sep_ratio_vs_min_error())
      plot_.add_caption('Average min 0-1 error vs separation ratio.')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_sep_ratio_vs_accept_ratio())
      plot_.add_caption('Average accept ratio vs separation ratio.')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_sep_ratio_vs_mix_ratio())
      plot_.add_caption('Average mixing ratio vs separation ratio.')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_sep_ratio_vs_visit_ratio())
      plot_.add_caption('Average visiting ratio vs separation ratio.')
    plt.close()

    doc.generate_pdf(clean_tex=True)

  def _create_specs_table(self, doc):
    """Generates summary table."""

    col_names = ['Model',
                 'Dataset',
                 'Data Size',
                 "beta_0",
                 'Swap Step',
                 'Burn In',
                 'Batch Size',
                 'Noise Type',
                 'Proba Coeff']

    table_spec = "|@{}l@{}".join(['' for i in range(len(col_names) + 1)]) + '|'

    tabular = tex.Tabular(table_spec,
                          pos=self._position,
                          booktabs=False,
                          row_height=0.1,)


    with doc.create(tabular) as table:
      table.add_hline()
      table.add_row(col_names)
      table.add_hline()
      for i, mse in enumerate(self._mses):
        for summ_ext in mse._summ_ext:
          vals_ = {n:[] for n in col_names}
          se = mse._summ_ext[summ_ext]
          desc = se.get_description()
          vals_['Model'].append(s_utils.get_value_from_name(
              se.get_name(), 'model_name'))
          vals_['Dataset'].append(s_utils.get_value_from_name(
              se.get_name(), 'dataset_name'))
          vals_['Data Size'].append(s_utils.get_value_from_name(
              se.get_name(), 'train_data_size'))
          vals_["beta_0"].append(s_utils.get_value_from_name(
              se.get_name(), 'beta_0'))
          vals_['Swap Step'].append(desc['swap_step'])
          vals_['Burn In'].append(desc['burn_in_period'])
          vals_['Batch Size'].append(desc['batch_size'])
          vals_['Noise Type'].append(desc['noise_type'])
          vals_['Proba Coeff'].append(desc['proba_coeff'])

        for k in vals_:
          vals_[k] = list(set(vals_[k]))
        row = []
        for col_name in col_names:
          if len(vals_[col_name]) == 1:
            row.append(tex.basic.TextColor(self._colors[i],
                                           str(vals_[col_name][0])))
          else:
            row.append(' ')

        table.add_row(row)
        table.add_hline()


  def _plot_diffusion_vs_min_error(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()
    for i, mse in enumerate(self._mses):
      diff_vals, err_vals, seps = (
          mse.get_diffusion_vs_min_error())
      annotation = [(str(seps[j]), diff_vals[j], err_vals[j])
                    for j in range(len(diff_vals))]

      figs.append(plot.plot(x=diff_vals,
                            y=err_vals,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i],
                            annotate=annotation))
    plot.legend(fig,
                ax,
                xlabel='AVERAGE DIFFUSION',
                ylabel='AVERAGE MIN 0-1 ERROR',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))

    img_path = os.path.join(self._images_dirname, 'diffusion.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_n_steps_vs_min_error(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()
    for i, mse in enumerate(self._mses):
      step_vals, err_vals, seps = (
          mse.get_n_steps_vs_min_error())
      annotation = [(str(seps[j]), step_vals[j], err_vals[j])
                    for j in range(len(step_vals))]
      figs.append(plot.plot(x=step_vals,
                            y=err_vals,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i],
                            annotate=annotation))
    plot.legend(fig,
                ax,
                xlabel='AVERAGE EPOCHS',
                ylabel='AVERAGE MIN 0-1 ERROR',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))

    img_path = os.path.join(self._images_dirname, 'n_steps.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_sep_ratio_vs_min_error(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()

    for i, mse in enumerate(self._mses):
      seps, errs, stddevs = mse.get_sep_ratio_vs_min_error()

      figs.append(plot.plot(x=seps,
                            y=errs,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i]))
    plot.legend(fig,
                ax,
                xlabel='SEPARATION RATIO',
                ylabel='AVERAGE MIN 0-1 ERROR',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))
    img_path = os.path.join(self._images_dirname, 'min_loss_sep.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_sep_ratio_vs_accept_ratio(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()

    for i, mse in enumerate(self._mses):
      seps, accs, errs = mse.get_sep_ratio_vs_accept_ratio()

      figs.append(plot.plot(x=seps,
                            y=accs,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i]))
    plot.legend(fig,
                ax,
                xlabel='SEPARATION RATIO',
                ylabel='ACCEPT RATIO',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))
    img_path = os.path.join(self._images_dirname, 'sep_vs_accept.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_sep_ratio_vs_mix_ratio(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()

    for i, mse in enumerate(self._mses):
      seps, mixs, errs = mse.get_sep_ratio_vs_mix_ratio()

      figs.append(plot.plot(x=seps,
                            y=mixs,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i]))
    plot.legend(fig,
                ax,
                xlabel='SEPARATION RATIO',
                ylabel='MIXING RATIO',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))
    img_path = os.path.join(self._images_dirname, 'sep_vs_mix.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_sep_ratio_vs_visit_ratio(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()

    for i, mse in enumerate(self._mses):
      seps, visits, errs = mse.get_sep_ratio_vs_visit_ratio()

      figs.append(plot.plot(x=seps,
                            y=visits,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i]))
    plot.legend(fig,
                ax,
                xlabel='SEPARATION RATIO',
                ylabel='VISIT RATIO',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))
    img_path = os.path.join(self._images_dirname, 'sep_vs_visit.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_sep_ratio_vs_err_differ(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()

    for i, mse in enumerate(self._mses):
      seps, visits, errs = mse.get_sep_ratio_vs_err_differ()

      figs.append(plot.plot(x=seps,
                            y=visits,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i]))
    plot.legend(fig,
                ax,
                xlabel='SEPARATION RATIO',
                ylabel='OVERFITTING ERROR',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))
    img_path = os.path.join(self._images_dirname, 'sep_vs_min_overfit.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_sep_ratio_vs_final_err_differ(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()

    for i, mse in enumerate(self._mses):
      seps, visits, errs = mse.get_sep_ratio_vs_final_err_differ()

      figs.append(plot.plot(x=seps,
                            y=visits,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i]))
    plot.legend(fig,
                ax,
                xlabel='SEPARATION RATIO',
                ylabel='FINAL OVERFITTING ERROR',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))
    img_path = os.path.join(self._images_dirname, 'sep_vs_final_overfit.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path




class MultiSummaryExtractor:

  def __init__(self, names):
    """Instantiates a new MultiSummaryExtractor instance.

    Args:
      `names`: A list of simulation names.

    Raises:
      ValueError: If for any simulation name in `names` the simulation
        do not exist.
      TypeError: If `names` is not `list` or `names` is an empty list.
    """
    dirname = os.path.abspath(os.path.dirname(__file__))
    self._dirname = os.path.join(dirname, 'summaries')
    filenames = os.listdir(self._dirname)

    if not isinstance(names, list) or not names:
      raise TypeError("`names` argument must be non-empty list.")
    if any(name not in filenames for name in names):
      raise ValueError('The following simulation(s) do not exist(s):',
                       [name for name in names if name not in filenames])
    self._summ_ext = {
        name:SummaryExtractor(name)
        for name in names
    }

  def get_sep_ratio_vs_accept_ratio(self):
    """Returns data (sep_ratio list, `accept_ratio` list, stddev list)."""

    sep_ratios = []
    accept_ratios = []
    errs = []

    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, acc, stddev = se.get_sep_ratio_vs_accept_ratio()
      sep_ratios.append(sep)
      accept_ratios.append(acc)
      errs.append(stddev)

    x, y, z = zip(*sorted(zip(sep_ratios, accept_ratios, errs)))

    return list(x), list(y), list(z)

  def get_sep_ratio_vs_mix_ratio(self):
    """Returns data (sep_ratio list, `accept_ratio` list, stddev list)."""

    sep_ratios = []
    mix_ratios = []
    errs = []

    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, mix, stddev = se.get_sep_ratio_vs_mix_ratio()
      sep_ratios.append(sep)
      mix_ratios.append(mix)
      errs.append(stddev)

    x, y, z = zip(*sorted(zip(sep_ratios, mix_ratios, errs)))

    return list(x), list(y), list(z)

  def get_sep_ratio_vs_visit_ratio(self):
    """Returns data (sep_ratio list, `accept_ratio` list, stddev list)."""

    sep_ratios = []
    visit_ratios = []
    errs = []

    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, visit, stddev = se.get_sep_ratio_vs_visit_ratio()
      sep_ratios.append(sep)
      visit_ratios.append(visit)
      errs.append(stddev)

    x, y, z = zip(*sorted(zip(sep_ratios, visit_ratios, errs)))

    return list(x), list(y), list(z)

  def get_diffusion_vs_min_error(self):
    sep_ratios = []
    diff_vals = []
    errs = []

    for name in self._summ_ext:
      se = self._summ_ext[name]
      diff_val, diff_err, loss_val, loss_err, sep = (
          se.get_diffusion_vs_min_error())
      sep_ratios.append(sep)
      diff_vals.append(diff_val)
      errs.append(loss_val)

    x, y, z = zip(*sorted(zip(diff_vals, errs, sep_ratios)))

    return list(x), list(y), list(z)

  def get_n_steps_vs_min_error(self):
    sep_ratios = []
    err_vals = []
    step_vals = []


    for name in self._summ_ext:
      se = self._summ_ext[name]
      step_val, step_err, loss_val, loss_err, sep = (
          se.get_n_steps_vs_min_error())
      sep_ratios.append(sep)
      step_vals.append(step_val)
      err_vals.append(loss_val)

    x, y, z = zip(*sorted(zip(step_vals, err_vals, sep_ratios)))

    return list(x), list(y), list(z)

  def get_sep_ratio_vs_min_error(self):
    sep_ratios = []
    err_vals = []
    err_errs = []

    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, loss_val, loss_err = se.get_sep_ratio_vs_min_error()
      sep_ratios.append(sep)
      err_vals.append(loss_val)
      err_errs.append(loss_err)

    x, y, z = zip(*sorted(zip(sep_ratios, err_vals, err_errs)))

    return list(x), list(y), list(z)

  def get_sep_ratio_vs_err_differ(self):
    sep_ratios = []
    err_vals = []
    err_errs = []

    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, differ, differ_std = se.get_sep_ratio_vs_err_differ()
      sep_ratios.append(sep)
      err_vals.append(differ)
      err_errs.append(differ_std)

    x, y, z = zip(*sorted(zip(sep_ratios, err_vals, err_errs)))

    return list(x), list(y), list(z)

  def get_sep_ratio_vs_final_err_differ(self):
    sep_ratios = []
    err_vals = []
    err_errs = []

    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, differ, differ_std = se.get_sep_ratio_vs_final_err_differ()
      sep_ratios.append(sep)
      err_vals.append(differ)
      err_errs.append(differ_std)

    x, y, z = zip(*sorted(zip(sep_ratios, err_vals, err_errs)))

    return list(x), list(y), list(z)

class SummaryReportGenerator:
  """Generates pdf report for individual simulations."""

  _colors = plt.rcParams['axes.prop_cycle'].by_key()['color']
  _colors += ['blue',
              'orange',
              'purple',
              'dimgray',
              'maroon',
              'gold',
              'rosybrown',
              'tomato']
  _colors += _colors
  def __init__(self, names, labels, simulation_num=0, report_name='summary_report',
               sample_every=1, lower=500, higher=700, include_fnames=False, **kwargs):
    """Instantiates `SummaryReportGenerator` instance.
    
    Args:
      names: A list of filenames to process.
      labels: A list of labels to assign for each of the filename.
      simulation_num: A number of simulation for which to generate the
        report.
      report_name: A filename of the resulted PDF report.
      sample_every: A number specifying the interval s.t. the
        resulting plots will be sampled.
      lower: 
      higher:
      include_fnames: If `True`, adds image filename to the caption.
      kwargs:
        ylim_err: Tuple of two numbers specifying the limit for
          y-axis for error plots.
        ylim_loss: Tuple of two numbers specifying the limit for
          y-axis for loss plots.
        epoch_range: 

     **TODO**: make separate yaxis_cycle for error and loss.
    """
    self._include_fnames = include_fnames
    self._pathdelim = ('/' if 'win' not in sys.platform else '\\')
    self._simulation_num = simulation_num
    self._summ_ext = {f:SummaryExtractor(f) for f in names}
    self._original_names = []
    for i, name in enumerate(names):
      self._original_names.append(self._summ_ext[name]._name)
      self._summ_ext[name]._original_name = self._summ_ext[name]._name
      self._summ_ext[name]._name = labels[i]
    dirname = os.path.abspath(os.path.dirname(__file__))
    dirname = os.path.join(dirname, 'summaries', 'reports')
    if not os.path.exists(dirname):
      os.makedirs(dirname)

    self._dirname = os.path.join(dirname, report_name)
    self._images_dirname = os.path.join(self._dirname, 'images')
    self._pdf_filename = os.path.join(self._dirname, report_name)
    self._sample_every = sample_every
    if not os.path.exists(self._images_dirname):
      os.makedirs(self._images_dirname)

    self._width = r'1\textwidth'
    self._position = 'ht'
    self.yaxis_cycle = cycler(y=[0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72])
    self.sgd_color_cycler = cycler(color=['black', 'black'])
    self.lower = lower
    self.higher = higher
    self.ylim_err = kwargs.get('ylim_err', (0, 1))
    self.ylim_loss = kwargs.get('ylim_loss', (0, 5))
    epoch_range = (kwargs.get('epoch_range', None)
                  or (0, max(se.get_description()['n_epochs'] for se in self._summ_ext.values()))) 
    self.epoch_range = epoch_range
  def generate_report(self, custom_text="Results"):
    """Generates pdf file with report for for multiple individual simulations.

    Args:
      `custom_text`: A text that will be added to the beginning of the
        pdf file.
    """
    doc = tex.Document(self._pdf_filename,
                       font_size='tiny')
    doc.append(custom_text)
    doc.append(tex.LineBreak())

    self._create_specs_table(doc)
    #################### Min vals for error and loss ####################
    with doc.create(tex.Figure(position=self._position)) as plot_:
      imgpath = self._plot_train_test_min_error(self._sample_every,
                                                self._simulation_num,
                                                ylim=self.ylim_err,
                                                xlim=self.epoch_range)
      plot_.add_image(imgpath)
      caption = 'Train-test min error'
      if self._include_fnames:
        caption += '. Filename: ' + imgpath.split(self._pathdelim)[-1]
      plot_.add_caption(caption)
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      imgpath = self._plot_train_test_min_loss(self._sample_every,
                                               self._simulation_num,
                                               ylim=self.ylim_loss)
      plot_.add_image(imgpath)
      caption = 'Train-test min loss'
      if self._include_fnames:
        caption += '. Filename: ' + imgpath.split(self._pathdelim)[-1]
      plot_.add_caption(caption)
    plt.close()

    #################### Min vals for error and loss + logscaled ####################
    with doc.create(tex.Figure(position=self._position)) as plot_:
      imgpath = self._plot_train_test_min_error(self._sample_every,
                                                self._simulation_num,
                                                ylim=(0.05, 0.6),
                                                xlim=(50, 2000),
                                                log_x=4,
                                                store_image=False)
      imgpath = ''.join(imgpath.split('.')[:-1]) + '_logscaled.png'
      plt.savefig(imgpath, bbox_inches='tight')
      plt.close()
      plot_.add_image(imgpath)
      caption = 'Train-test min error'
      if self._include_fnames:
        caption += '. Filename: ' + imgpath.split(self._pathdelim)[-1]
      plot_.add_caption(caption)

    doc.append(tex.basic.NewPage())

    #################### Plots with diffusion ####################
    for name, se in self._summ_ext.items():
      with doc.create(tex.Figure(position=self._position)) as plot_:
        imgpath = self._plot_train_test_error_epochs_diffusion(
            se, self._simulation_num, ylim=self.ylim_err)
        plot_.add_image(imgpath)
        caption = 'Train-Test Error vs Diffusion vs Epochs for ' + str(se.get_name())
        if self._include_fnames:
          caption += '. Filename: ' + imgpath.split(self._pathdelim)[-1]
        plot_.add_caption(caption)
      plt.close()

    for name, se in self._summ_ext.items():
      with doc.create(tex.Figure(position=self._position)) as plot_:
        imgpath = self._plot_train_test_loss_epochs_diffusion(
            se, self._simulation_num, ylim=self.ylim_loss)
        plot_.add_image(imgpath)
        caption = 'Train-Test Loss vs Diffusion vs Epochs for ' + str(se.get_name())
        if self._include_fnames:
          caption += '. Filename: ' + imgpath.split(self._pathdelim)[-1]
        plot_.add_caption(caption)
      plt.close()

    #################### Plots with diffusion and gaps ####################
    with doc.create(tex.Figure(position=self._position)) as plot_:
      imgpath = self._plot_train_test_error_gap_all(
          self._simulation_num, ylim=self.ylim_err)
      plot_.add_image(imgpath)
      caption = 'Train-Test Error Gap'
      if self._include_fnames:
        caption += tex.utils.escape_latex(' \n ') + imgpath.split(self._pathdelim)[-1]
      plot_.add_caption(caption)
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      imgpath = self._plot_train_test_loss_gap_all(
          self._simulation_num, ylim=self.ylim_loss)
      plot_.add_image(imgpath)
      caption = 'Train-Test Loss Gap'
      if self._include_fnames:
        caption += tex.utils.escape_latex(' \n ') + imgpath.split(self._pathdelim)[-1]
      plot_.add_caption(caption)
    plt.close()

    #################### Plots of everything together ####################
    for name, se in self._summ_ext.items():
      with doc.create(tex.Figure(position=self._position)) as plot_:
        imgpath = self._plot_train_test_error_per_sim(se,
                                                      self._sample_every,
                                                      self._simulation_num,
                                                      ylim=self.ylim_err)
        plot_.add_image(imgpath)
        caption = 'Train-test error for ' + se.get_name()
        if self._include_fnames:
          caption += '. Filename: ' + imgpath.split(self._pathdelim)[-1]
        plot_.add_caption(caption)
      plt.close()

    for name, se in self._summ_ext.items():
      with doc.create(tex.Figure(position=self._position)) as plot_:
        imgpath = self._plot_train_test_loss_per_sim(se,
                                                     self._sample_every,
                                                     self._simulation_num,
                                                     ylim=self.ylim_loss)
        plot_.add_image(imgpath)
        caption = 'Train-test loss for ' + se.get_name()
        if self._include_fnames:
          caption += '. Filename: ' + imgpath.split(self._pathdelim)[-1]
        plot_.add_caption(caption)
      plt.close()

    doc.append(tex.basic.NewPage())

    #################### Plots of temperature mixing ####################
    for name, se in self._summ_ext.items():
      with doc.create(tex.Figure(position=self._position)) as plot_:
        imgpath = self._plot_mixing(se, self._simulation_num)
        plot_.add_image(imgpath)
        caption = 'Mixing ' + se.get_name()
        if self._include_fnames:
          caption += '. Filename: ' + imgpath.split(self._pathdelim)[-1]
        plot_.add_caption(caption)
      plt.close()

    #################### Plots of diffusions ####################
    for name, se in self._summ_ext.items():
      with doc.create(tex.Figure(position=self._position)) as plot_:
        imgpath = self._plot_diffusion(se, self._simulation_num)
        plot_.add_image(imgpath)
        caption = 'Diffusion ' + se.get_name()
        if self._include_fnames:
          caption += '. Filename: ' + imgpath.split(self._pathdelim)[-1]
        plot_.add_caption(caption)
      plt.close()
    
    for name, se in self._summ_ext.items():
      n_replicas = se.get_description()['n_replicas']
      if n_replicas == 1:
        imgpath = self._plot_loss_histogram_for_noise_level(se,)
        with doc.create(tex.Figure(position=self._position)) as plot_:
          plot_.add_image(imgpath)
          caption = ("Histogram of energy distributions for " + se.get_name())
          if self._include_fnames:
            caption += '. Filename: ' + imgpath.split(self._pathdelim)[-1]
          plot_.add_caption(caption)
          plt.close()

      else:
        for i in range(n_replicas - 1):
          noise_levels = [i, i+1]
          imgpath = self._plot_loss_histogram_for_noise_level(
              se, noise_level=noise_levels)
          with doc.create(tex.Figure(position=self._position)) as plot_:
            plot_.add_image(imgpath)
            caption = ("Histogram of energy distributions for "
                      + se.get_name()
                      + " for Noise Levels: "
                      + '-'.join([str(x) for x in noise_levels])
                      + '.')
            if self._include_fnames:
              caption += '. Filename: ' + imgpath.split(self._pathdelim)[-1]
            plot_.add_caption(caption)
            plt.close()
    
    # m\clearpage must be added. Otherwise overflow
    doc.append(tex.basic.NewPage())

    #################### MOA weights values ####################
    if any(('mode' in se.get_description()
            and se.get_description()['mode'] is not None
            and 'moa' == se.get_description()['mode'].lower())
            for name, se in self._summ_ext.items()):
      for name, se in self._summ_ext.items():
        if se.get_description()['n_replicas'] != 1:
          with doc.create(tex.Figure(position=self._position)) as plot_:
            se._plot_moa_weights(self._simulation_num)
            imgname = 'moa_weights_vals_' + se.get_name().replace(' ', '') + '.png'
            imgpath = os.path.join(self._images_dirname,
                                   imgname)
            plt.savefig(imgpath, bbox_inches='tight')
            plot_.add_image(imgpath)
            caption = 'Weight values of each replica for ' + se.get_name()
            if self._include_fnames:
              caption += '. Filename: ' + imgname
            plot_.add_caption(caption)
            plt.close()

    

      #################### Histograms of noise levels ####################
      # find rank in terms of min test error for each one of the
      # replicas
    for name, se in self._summ_ext.items():
      if (se.get_description()['n_replicas'] == 1
          or se.get_description()['burn_in_period']==np.inf):
        continue
      errs = {}
      for r in range(se.get_description()['n_replicas']):
        x, y = se.get_summary('test_error',
                              replica_id=r,
                              simulation_num=self._simulation_num)
        errs[r] = min(y)

      sorted_errs = sorted(list(errs.items()), key=lambda x: x[1])
      rids_errs_ranks = [(r[0], r[1], i) for i, r in enumerate(sorted_errs)]
      rids = [r[0] for r in rids_errs_ranks]

      for r in rids_errs_ranks:
        with doc.create(tex.Figure(position=self._position)) as plot_:
          imgpath = self._plot_noise_level_histogram(
              se, replica_id=r[0], simulation_num=self._simulation_num)
          plot_.add_image(imgpath)
          caption = ('Histogram of noise levels for replica '
                      + str(r[0])
                      + " for "
                      + se.get_name()
                      + ".\nMin Test Error: "
                      + str(r[1])
                      + ", Rank: "
                      + str(r[2]+1)
                      + "/"
                      + str(se.get_description()['n_replicas']))
          if self._include_fnames:
            caption += '. Filename: ' + imgpath.split(self._pathdelim)[-1]
          plot_.add_caption(caption)
          plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      imgpath = self._plot_train_test_min_error_with_markers(
          self._sample_every, self._simulation_num, ylim=self.ylim_err,
          lower=self.lower, higher=self.higher)
      plot_.add_image(imgpath)
      caption = 'Train-test min error with swap markers'
      if self._include_fnames:
        caption += '. Filename: ' + imgpath.split(self._pathdelim)[-1]
      plot_.add_caption(caption)

    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      imgpath = self._plot_train_test_min_loss_with_markers(self._sample_every,
                                                            self._simulation_num,
                                                            ylim=self.ylim_loss,
                                                            lower=self.lower,
                                                            higher=self.higher)
      plot_.add_image(imgpath)
      caption = 'Train-test min loss with swap markers'
      if self._include_fnames:
        caption += '. Filename: ' + imgpath.split(self._pathdelim)[-1]
      plot_.add_caption(caption)
    plt.close()
    '''
    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_train_test_error(self._sample_every,
                                                  self._simulation_num))
      plot_.add_caption('Train-test error (everything together)')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_train_test_loss(self._sample_every,
                                                 self._simulation_num))
      plot_.add_caption('Train-test loss (everything together)')
    plt.close()
    '''
    doc.generate_pdf(clean_tex=True)

  def _get_next_sgd_color(self):
    for color in self.sgd_color_cycler*100:
      yield color

  def generate_min_loss_err_report(self, simulation_nums, custom_text='Results'):
    doc = doc = tex.Document(self._pdf_filename,
                       font_size='tiny')
    doc.append(custom_text)
    doc.append(tex.LineBreak())

    self._create_specs_table(doc)
    for s in simulation_nums:
      with doc.create(tex.Figure(position=self._position)) as plot_:
        plot_.add_image(self._plot_train_test_min_error(self._sample_every,
                                                        simulation_num=s))
        plot_.add_caption('Train-test min error ' + str(s))
      plt.close()

      with doc.create(tex.Figure(position=self._position)) as plot_:
        plot_.add_image(self._plot_train_test_min_loss(self._sample_every,
                                                       simulation_num=s))
        plot_.add_caption('Train-test min loss ' + str(s))
      plt.close()
    doc.generate_pdf(clean_tex=True)

  def _plot_train_test_error(self, sample_every=1, simulation_num=0):
    fig, ax = plt.subplots()
    plot = Plot()

    color_idx = 0
    for name in self._summ_ext:
      se = self._summ_ext[name]

      for r in range(se.get_description()['n_replicas']):

        x, y = se.get_summary(summ_name='test_error',
                              replica_id=r,
                              simulation_num=self._simulation_num)
        x1, y1 = se.get_summary(summ_name='train_error',
                                replica_id=r,
                                simulation_num=self._simulation_num)
        n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1

        if se.get_description()['n_replicas'] == 1:
          #label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
          #label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
          label_test = se.get_name() + ' Test error'
          label_train = se.get_name() + ' Train error'
          #color = 'black'
          color = self._get_next_sgd_color().__next__()['color']
          linestyle_test = '-'
          linestyle_train = '--'
          linewidth_train = 2
          linewidth_test = 2
        else:
          #label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
          #label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
          label_test = se.get_name() + ' Test error (replica ' + str(r) + ')'
          label_train = se.get_name() + ' Train error (replica ' + str(r) + ')'
          color = self._colors[color_idx]
          linestyle_test = '-'
          linestyle_train = '--'
          linewidth_train = 1.5
          linewidth_test = 1.5
          color_idx += 1

        plot.plot(x,
                  y,
                  fig=fig,
                  ax=ax,
                  label=label_test,
                  linewidth=linewidth_test,
                  color=color,
                  linestyle=linestyle_test,
                  splined_points_mult=None)

        #y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
        #y1 = y1[::sample_every]


        plot.plot(np.linspace(start=0, stop=n_epochs, num=len(y1)),
                  y1,
                  fig=fig,
                  ax=ax,
                  label=label_train,
                  linewidth=linewidth_train,
                  linestyle=linestyle_train,
                  color=color,
                  splined_points_mult=None)

    plot.legend(fig=fig,
                ax=ax,
                xlabel='EPOCHS',
                ylabel='ERROR',)
    img_path = os.path.join(self._images_dirname, 'train_test_error.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_min_error_with_markers(self, sample_every=1, simulation_num=0, ylim=(0, 1), lower=500, higher=700):

    def _get_next_yloc():
      for y in self.yaxis_cycle*10000:
        yield y['y']
    fig, ax = plt.subplots()
    plot = Plot()
    color_idx = 0
    added_noise_keys = None
    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, loss_val, loss_err = se.get_sep_ratio_vs_min_error()
      min_rid = se._vals['replica_id_min_err_sim_' + str(simulation_num)]
      x, y = se.get_summary(summ_name='test_error',
                            replica_id=min_rid,
                            simulation_num=simulation_num)
      x1, y1 = se.get_summary(summ_name='train_error',
                              replica_id=min_rid,
                              simulation_num=simulation_num)
      n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1
      prev_x = x.copy()
      prev_x1 = x1.copy()
      x = [x[i] for i in range(len(y)) if lower <= prev_x[i] <= higher]
      y = [y[i] for i in range(len(y)) if lower <= prev_x[i] <= higher]

      x1 = [x1[i] for i in range(len(y1)) if lower <= prev_x1[i] <= higher]
      y1 = [y1[i] for i in range(len(y1)) if lower <= prev_x1[i] <= higher]
      n_epochs = higher - lower
      if se.get_description()['n_replicas'] == 1:
        #label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        #label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        #color = 'black'
        label_test = se.get_name() + ' Test error (replica ' + str(min_rid) + ')'
        label_train = se.get_name() + ' Train error (replica ' + str(min_rid) + ')'
        color = self._get_next_sgd_color().__next__()['color']
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 2
        linewidth_test = 2
      else:
        #label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        #label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        label_test = se.get_name() + ' Test loss (error ' + str(min_rid) + ')'
        label_train = se.get_name() + ' Train loss (error ' + str(min_rid) + ')'
        color = self._colors[color_idx]
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 1.5
        linewidth_test = 1.5
        color_idx += 1

      plot.plot(x,
                y,
                fig=fig,
                ax=ax,
                label=label_test,
                linewidth=linewidth_test,
                color=color,
                linestyle=linestyle_test,
                splined_points_mult=None)

      plot.plot(x1,
                y1,
                fig=fig,
                ax=ax,
                label=label_train,
                linewidth=linewidth_train,
                linestyle=linestyle_train,
                color=color,
                splined_points_mult=None)
      x, noise_vals = se.get_summary(
          'noise_values', replica_id=min_rid, simulation_num=simulation_num)
      noises = sorted(list(set(noise_vals)))
      noises = [(n, i) for i, n in enumerate(noises)]
      noise_keys = {n:i for n, i in noises}
      next_yloc = _get_next_yloc()
      for i, noise in enumerate(noise_vals):

        if i > 0 and lower <= x[i] <= higher and noise != noise_vals[i-1]:
          ax.axvline(x[i])
          ax.text(x[i-1], next_yloc.__next__(), str(noise_keys[noise_vals[i-1]]) + '->' + str(noise_keys[noise]))
          added_noise_keys = noise_keys

    if added_noise_keys:
      xlabel = 'EPOCHS\n' + json.dumps(added_noise_keys)
    else:
      xlabel = 'EPOCHS'
    plot.legend(fig=fig,
                ax=ax,
                xlabel=xlabel,
                ylabel='ERROR',
                ylimit=ylim)
    img_path = os.path.join(self._images_dirname,
                            'train_test_min_error_with_markers' + str(simulation_num) + '.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_min_error(self,
                                 sample_every=1,
                                 simulation_num=0,
                                 ylim=(0, 1),
                                 xlim=None,
                                 log_y=None,
                                 log_x=None,
                                 store_image=True):
    fig, ax = plt.subplots()
    plot = Plot()

    color_idx = 0
    for name in self._summ_ext:
      se = self._summ_ext[name]
      if (se.get_description()['n_replicas'] != 1
          and 'mode' in se.get_description()
          and se.get_description()['mode'] is not None
          and se.get_description()['mode'].lower() == 'moa'):
        train_label = se.get_name() + ' Train error (MOA)'
        test_label = se.get_name() + ' Test error (MOA)'
        train_summ_name = 'moa_train_error'
        test_summ_name = 'moa_test_error'
        test_linestyle = '-'
        train_linestyle = '--'
        x, y = se.get_summary(test_summ_name, simulation_num=simulation_num)
        plot.plot(x, y, fig=fig, ax=ax, label=test_label, linestyle=test_linestyle,
                  color=self._colors[color_idx])
        x, y = se.get_summary(train_summ_name, simulation_num=simulation_num)
        plot.plot(x, y, fig=fig, ax=ax, label=train_label, linestyle=train_linestyle,
                  color=self._colors[color_idx])
        color_idx += 1

      sep, loss_val, loss_err = se.get_sep_ratio_vs_min_error()
      min_rid = se._vals['replica_id_min_err_sim_' + str(simulation_num)]
      x, y = se.get_summary(summ_name='test_error',
                            replica_id=min_rid,
                            simulation_num=simulation_num)
      x1, y1 = se.get_summary(summ_name='train_error',
                              replica_id=min_rid,
                              simulation_num=simulation_num)
      n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1

      if se.get_description()['n_replicas'] == 1:
        #label_test = se.get_name() + ' test ' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        #label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        label_test = se.get_name() + ' Test error'
        label_train = se.get_name() + ' Train error'
        #color = 'black'
        color = self._get_next_sgd_color().__next__()['color']
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 2
        linewidth_test = 2
      else:
        #label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        #label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        label_test = se.get_name() + ' Test error (replica ' + str(min_rid) + ')'
        label_train = se.get_name() + ' Train error (replica ' + str(min_rid) + ')'
        color = self._colors[color_idx]
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 1.5
        linewidth_test = 1.5
        color_idx += 1
      #y_vals = y[5:].copy()
      #chunkified = [(np.mean(s), int((idx + 1)*avg_interval/2))
      #              for idx, s in enumerate(y_vals[i:i+avg_interval] for i in range(0, len(y_vals), avg_interval))]
      #annots = [("{0:.3f}".format(c[0]), x[_find_nearest_idx(x, c[1])], )]
      plot.plot(x,
                y,
                fig=fig,
                ax=ax,
                label=label_test,
                linewidth=linewidth_test,
                color=color,
                linestyle=linestyle_test,
                splined_points_mult=None)

      #y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
      #y1 = y1[::sample_every]


      plot.plot(np.linspace(start=0, stop=n_epochs, num=len(y1)),
                y1,
                fig=fig,
                ax=ax,
                label=label_train,
                linewidth=linewidth_train,
                linestyle=linestyle_train,
                color=color,
                splined_points_mult=None)

    plot.legend(fig=fig,
                ax=ax,
                xlabel='EPOCHS',
                ylabel='ERROR',
                ylimit=ylim,
                xlimit=xlim,
                log_x=log_x,
                log_y=log_y)

    img_path = os.path.join(self._images_dirname,
                            'train_test_min_error' + str(simulation_num) + '.png')
    if store_image:
      plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_min_loss(self,
                                sample_every=1,
                                simulation_num=0,
                                ylim=(0, 5),
                                log_y=None,
                                epoch_lim=None):
    fig, ax = plt.subplots()
    plot = Plot()
    color_idx = 0

    for name in self._summ_ext:
      se = self._summ_ext[name]
      if (se.get_description()['n_replicas'] != 1
          and 'mode' in se.get_description()
          and se.get_description()['mode'] is not None
          and se.get_description()['mode'].lower() == 'moa'):

        train_label = se.get_name() + ' Train loss (MOA)'
        test_label = se.get_name() + ' Test loss (MOA)'
        train_summ_name = 'moa_train_loss'
        test_summ_name = 'moa_test_loss'
        test_linestyle = '-'
        train_linestyle = '--'
        x, y = se.get_summary(test_summ_name, simulation_num=simulation_num)
        plot.plot(x, y, fig=fig, ax=ax, label=test_label, linestyle=test_linestyle,
                  color=self._colors[color_idx])
        x, y = se.get_summary(train_summ_name, simulation_num=simulation_num)
        plot.plot(x, y, fig=fig, ax=ax, label=train_label, linestyle=train_linestyle,
                  color=self._colors[color_idx])
        color_idx += 1
      sep, loss_val, loss_err = se.get_sep_ratio_vs_min_error()
      min_rid = se._vals['replica_id_min_err_sim_' + str(simulation_num)]

      x, y = se.get_summary(summ_name='test_loss',
                            replica_id=min_rid,
                            simulation_num=simulation_num)
      x1, y1 = se.get_summary(summ_name='train_loss',
                              replica_id=min_rid,
                              simulation_num=simulation_num)
      n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1

      if se.get_description()['n_replicas'] == 1:
        #label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        #label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        label_test = se.get_name() + ' Test loss'
        label_train = se.get_name() + ' Train loss'
        #color = 'black'
        color = self._get_next_sgd_color().__next__()['color']
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 2
        linewidth_test = 2
      else:
        #label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        #label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        label_test = se.get_name() + ' Test loss (replica ' + str(min_rid) + ')'
        label_train = se.get_name() + ' Train loss (replica ' + str(min_rid) + ')'
        color = self._colors[color_idx]
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 1.5
        linewidth_test = 1.5
        color_idx += 1
      x = np.array(x)
      y = np.array(y)
      if epoch_lim is not None:
        indices = np.where(x <= epoch_lim)[0]
        x = x[indices]
        y = y[indices]

      plot.plot(x,
                y,
                fig=fig,
                ax=ax,
                label=label_test,
                linewidth=linewidth_test,
                color=color,
                linestyle=linestyle_test,
                splined_points_mult=None)

      #y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
      #y1 = y1[::sample_every]
      x1 = np.linspace(start=0, stop=n_epochs, num=len(y1))
      if epoch_lim is not None:
        indices = np.where(x1 <= epoch_lim)
        y1 = y1[indices]
        x1 = x1[indices]

      plot.plot(x1,
                y1,
                fig=fig,
                ax=ax,
                label=label_train,
                linewidth=linewidth_train,
                linestyle=linestyle_train,
                color=color,
                splined_points_mult=None)
    #if log_y is not None:

    plot.legend(fig=fig,
                ax=ax,
                xlabel='EPOCHS',
                ylabel='LOSS',
                ylimit=ylim)
    img_path = os.path.join(self._images_dirname,
                            'train_test_min_loss' + str(simulation_num) + '.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_error_epochs_diffusion(self, se, simulation_num=0, ylim=(0, 1)):
    se._plot_diffusion_vs_min_error(simulation_num=simulation_num, ylim=ylim)
    img_path = os.path.join(
        self._images_dirname,
        'train_test_error_epochs_diffusion'+se.get_name().replace(' ', '')+'.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path
  
  def _plot_train_test_loss_epochs_diffusion(self, se, simulation_num=0, ylim=(0, 5)):
    se._plot_diffusion_vs_min_loss(simulation_num=simulation_num,
                                   ylim=ylim)
    img_path = os.path.join(
        self._images_dirname,
        'train_test_loss_epochs_diffusion'+se.get_name().replace(' ', '')+'.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_error_gap(self, se, simulation_num=0, ylim=(0, 1)):
    se._plot_train_test_error_gap(simulation_num, ylim=ylim)
    img_path = os.path.join(
        self._images_dirname,
        'train_test_error_gap_diffusion'+se.get_name().replace(' ', '')+'.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_error_gap_all(self, simulation_num=0, ylim=(0, 1), linewidth=1.2):
    """Plots `_plot_train_test_error_gap` for all simulations together."""
    fig = plt.figure(figsize=(18, 10))
    ax = fig.gca(projection='3d')
    for i, name in enumerate(self._summ_ext):
      se = self._summ_ext[name]
      #if se.get_description()['n_replicas'] == 1:
      #  continue
      x_gap, y_gap, x_diff, result = se._data_for_train_test_error_gap(
          simulation_num=simulation_num, ylim=ylim)
      

      ax.plot(x_gap, y_gap, np.zeros(len(result['test'])),
              color=se._colors[i], linewidth=linewidth,
              label='Test-Train Error Gap for ' + se.get_name())
      ax.plot(x_gap, ylim[1]*np.ones(len(result['test'])), result['diff'],
              color=se._colors[i], linewidth=linewidth)

    ax.view_init(20, 270)
    xlabel = ('EPOCHS\n'
        + 'Gap-Diffusion Corr: '
        + "{0:.2f}".format(pearsonr(y_gap, result['diff'])[0]))
    plt.xlabel(xlabel, labelpad=20)
    plt.ylabel('Error Gap')
    plt.ylim(min(0, min(y_gap)), ylim[1])
    ax.set_zlabel('Diffusion')
    plt.legend()
    img_path = os.path.join(
        self._images_dirname,
        'train_test_error_gap_diffusion_all'+se.get_name().replace(' ', '')+'.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_loss_gap(self, se, simulation_num=0, ylim=(0, 5)):
    se._plot_train_test_loss_gap(simulation_num, ylim=ylim)
    img_path = os.path.join(
        self._images_dirname,
        'train_test_loss_gap_diffusion'+se.get_name().replace(' ', '')+'.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_loss_gap_all(self, simulation_num=0, ylim=(0, 1), linewidth=1.2):
    """Plots `_plot_train_test_loss_gap` for all simulations together."""
    fig = plt.figure(figsize=(18, 10))
    ax = fig.gca(projection='3d')
    for i, name in enumerate(self._summ_ext):
      se = self._summ_ext[name]
      #if se.get_description()['n_replicas'] == 1:
      #  continue
      x_gap, y_gap, x_diff, result = se._data_for_train_test_loss_gap(
          simulation_num=simulation_num, ylim=ylim)
      

      ax.plot(x_gap, y_gap, np.zeros(len(result['test'])),
              color=se._colors[i], linewidth=linewidth,
              label='Test-Train Loss Gap for ' + se.get_name())
      ax.plot(x_gap, ylim[1]*np.ones(len(result['test'])), result['diff'],
              color=se._colors[i], linewidth=linewidth)

    ax.view_init(20, 270)
    xlabel = ('EPOCHS\n'
        + 'Gap-Diffusion Corr: '
        + "{0:.2f}".format(pearsonr(y_gap, result['diff'])[0]))
    plt.xlabel(xlabel, labelpad=20)
    plt.ylabel('Loss Gap')
    plt.ylim(min(0, min(y_gap)), ylim[1])
    ax.set_zlabel('Diffusion')
    plt.legend()
    img_path = os.path.join(
        self._images_dirname,
        'train_test_loss_gap_diffusion_all'+se.get_name().replace(' ', '')+'.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_min_loss_with_markers(
      self, sample_every=1, simulation_num=0, ylim=(0, 5), lower=500, higher=700):
    #yaxis_cycle = cycler(y=[0.66, 0.68, 0.7, 0.72, 0.7, 0.68])
    def _get_next_yloc():
      for y in self.yaxis_cycle*10000:
        yield y['y']/3
    fig, ax = plt.subplots()
    plot = Plot()
    color_idx = 0
    added_noise_keys = None
    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, loss_val, loss_err = se.get_sep_ratio_vs_min_error()
      min_rid = se._vals['replica_id_min_err_sim_' + str(simulation_num)]
      x, y = se.get_summary(summ_name='test_loss',
                            replica_id=min_rid,
                            simulation_num=simulation_num)
      x1, y1 = se.get_summary(summ_name='train_loss',
                              replica_id=min_rid,
                              simulation_num=simulation_num)
      n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1
      prev_x = x.copy()
      prev_x1 = x1.copy()
      x = [x[i] for i in range(len(y)) if lower <= prev_x[i] <= higher]
      y = [y[i] for i in range(len(y)) if lower <= prev_x[i] <= higher]

      x1 = [x1[i] for i in range(len(y1)) if lower <= prev_x1[i] <= higher]
      y1 = [y1[i] for i in range(len(y1)) if lower <= prev_x1[i] <= higher]
      n_epochs = higher - lower
      if se.get_description()['n_replicas'] == 1:
        #label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        #label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        #color = 'black'
        label_test = se.get_name() + ' Test loss'
        label_train = se.get_name() + ' Train loss'
        color = self._get_next_sgd_color().__next__()['color']
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 2
        linewidth_test = 2
      else:
        #label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        #label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        label_test = se.get_name() + ' Test loss (replica ' + str(min_rid) + ')'
        label_train = se.get_name() + ' Train loss (replica ' + str(min_rid) + ')'
        color = self._colors[color_idx]
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 1.5
        linewidth_test = 1.5
        color_idx += 1

      plot.plot(x,
                y,
                fig=fig,
                ax=ax,
                label=label_test,
                linewidth=linewidth_test,
                color=color,
                linestyle=linestyle_test,
                splined_points_mult=None)

      plot.plot(x1,
                y1,
                fig=fig,
                ax=ax,
                label=label_train,
                linewidth=linewidth_train,
                linestyle=linestyle_train,
                color=color,
                splined_points_mult=None)
      x, noise_vals = se.get_summary('noise_values', replica_id=min_rid, simulation_num=simulation_num)
      noises = sorted(list(set(noise_vals)))
      noises = [(n, i) for i, n in enumerate(noises)]
      noise_keys = {n:i for n, i in noises}
      next_yloc = _get_next_yloc()
      text_loc = ylim[1]
      for i, noise in enumerate(noise_vals):

        if i > 0 and lower <= x[i] <= higher and noise != noise_vals[i-1]:
          ax.axvline(x[i])
          ax.text(x[i-1], text_loc + next_yloc.__next__()*5, str(noise_keys[noise_vals[i-1]]) + '->' + str(noise_keys[noise]))
          added_noise_keys = noise_keys

    if added_noise_keys:
      xlabel = 'EPOCHS\n' + json.dumps(added_noise_keys)
    else:
      xlabel = 'EPOCHS'
    plot.legend(fig=fig,
                ax=ax,
                xlabel=xlabel,
                ylabel='ERROR',
                ylimit=ylim)
    img_path = os.path.join(self._images_dirname,
                            'train_test_min_loss_with_markers' + str(simulation_num) + '.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_loss(self, summ_name, sample_every=1, simulation_num=0):
    fig, ax = plt.subplots()
    plot = Plot()

    color_idx = 0
    for name in self._summ_ext:
      se = self._summ_ext[name]
      for r in range(se.get_description()['n_replicas']):
        x, y = se.get_summary(summ_name=summ_name,
                              replica_id=r,
                              simulation_num=simulation_num)
        if se.get_description()['n_replicas'] == 1:
          #color = 'black'
          color = self._get_next_sgd_color().__next__()['color']
        else:
          color = self._colors[color_idx]

  def _plot_train_test_loss(self, sample_every=1, simulation_num=0):
    fig, ax = plt.subplots()
    plot = Plot()

    color_idx = 0
    for name in self._summ_ext:
      se = self._summ_ext[name]

      for r in range(se.get_description()['n_replicas']):

        x, y = se.get_summary(summ_name='test_loss',
                              replica_id=r,
                              simulation_num=simulation_num)
        x1, y1 = se.get_summary(summ_name='train_loss',
                                replica_id=r,
                                simulation_num=simulation_num)
        n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1

        if se.get_description()['n_replicas'] == 1:
          #label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
          #label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
          label_test = se.get_name() + ' Test loss'
          label_train = se.get_name() + ' Train loss'
          #color = 'black'
          color = self._get_next_sgd_color().__next__()['color']
          linestyle_test = '-'
          linestyle_train = '--'
          linewidth_train = 2
          linewidth_test = 2
        else:
          #label_test = se.get_name() + ' Test loss' + str(r) + '_min:' + "{0:.3f}".format(min(y))
          #label_train = se.get_name() + ' Train loss' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
          label_test = se.get_name() + ' Test loss (replica ' + str(r) + ')'
          label_train = se.get_name() + ' Train loss (replica ' + str(r) + ')'
          color = self._colors[color_idx]
          linestyle_test = '-'
          linestyle_train = '--'
          linewidth_train = 1.5
          linewidth_test = 1.5
          color_idx += 1

        plot.plot(x,
                  y,
                  fig=fig,
                  ax=ax,
                  label=label_test,
                  linewidth=linewidth_test,
                  color=color,
                  linestyle=linestyle_test,
                  splined_points_mult=None)

        #y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
        #y1 = y1[::sample_every]


        plot.plot(np.linspace(start=0, stop=n_epochs, num=len(y1)),
                  y1,
                  fig=fig,
                  ax=ax,
                  label=label_train,
                  linewidth=linewidth_train,
                  linestyle=linestyle_train,
                  color=color,
                  splined_points_mult=None)

    plot.legend(fig=fig,
                ax=ax,
                xlabel='EPOCHS',
                ylabel='ERROR',)
    img_path = os.path.join(self._images_dirname, 'train_test_loss.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_error_per_sim(self, se, sample_every=1, simulation_num=0, ylim=(0, 1)):
    fig, ax = plt.subplots()
    plot = Plot()


    color_idx = 0
    for r in range(se.get_description()['n_replicas']):

      x, y = se.get_summary(summ_name='test_error',
                            replica_id=r,
                            simulation_num=simulation_num)
      x1, y1 = se.get_summary(summ_name='train_error',
                              replica_id=r,
                              simulation_num=simulation_num)
      n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1

      if se.get_description()['n_replicas'] == 1:
        #label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
        #label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
        label_test = se.get_name() + ' Test error'
        label_train = se.get_name() + ' Train error'
        #color = 'black'
        color = self._get_next_sgd_color().__next__()['color']
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 2
        linewidth_test = 2
      else:
        #label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
        #label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
        label_test = se.get_name() + ' Test error (replica ' + str(r) + ')'
        label_train = se.get_name() + ' Train error (replica ' + str(r) + ')'
        color = self._colors[color_idx]
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 1.5
        linewidth_test = 1.5
        color_idx += 1

      plot.plot(x,
                y,
                fig=fig,
                ax=ax,
                label=label_test,
                linewidth=linewidth_test,
                color=color,
                linestyle=linestyle_test,
                splined_points_mult=None)

      #y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
      #y1 = y1[::sample_every]


      plot.plot(np.linspace(start=0, stop=n_epochs, num=len(y1)),
                y1,
                fig=fig,
                ax=ax,
                label=label_train,
                linewidth=linewidth_train,
                linestyle=linestyle_train,
                color=color,
                splined_points_mult=None)

    plot.legend(fig=fig,
                ax=ax,
                xlabel='EPOCHS',
                ylabel='ERROR',
                ylimit=ylim)
    img_path = os.path.join(
        self._images_dirname,
        'train_test_error_per_sim'+se.get_name().replace(' ', '')+'.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_loss_per_sim(self, se, sample_every=1, simulation_num=0, ylim=(0, 5)):
    fig, ax = plt.subplots()
    plot = Plot()


    color_idx = 0
    for r in range(se.get_description()['n_replicas']):

      x, y = se.get_summary(summ_name='test_loss',
                            replica_id=r,
                            simulation_num=simulation_num)
      x1, y1 = se.get_summary(summ_name='train_loss',
                              replica_id=r,
                              simulation_num=simulation_num)
      n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1

      if se.get_description()['n_replicas'] == 1:
        #label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
        #label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
        #color = 'black'
        label_test = se.get_name() + ' Test loss'
        label_train = se.get_name() + ' Train loss'
        color = self._get_next_sgd_color().__next__()['color']
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 2
        linewidth_test = 2
      else:
        #label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
        #label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
        label_test = se.get_name() + ' Test loss (replica ' + str(r) + ')'
        label_train = se.get_name() + ' Train loss (replica ' + str(r) + ')'
        color = self._colors[color_idx]
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 1.5
        linewidth_test = 1.5
        color_idx += 1

      plot.plot(x,
                y,
                fig=fig,
                ax=ax,
                label=label_test,
                linewidth=linewidth_test,
                color=color,
                linestyle=linestyle_test,
                splined_points_mult=None)

      #y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
      #y1 = y1[::sample_every]


      plot.plot(np.linspace(start=0, stop=n_epochs, num=len(y1)),
                y1,
                fig=fig,
                ax=ax,
                label=label_train,
                linewidth=linewidth_train,
                linestyle=linestyle_train,
                color=color,
                splined_points_mult=None)

    plot.legend(fig=fig,
                ax=ax,
                xlabel='EPOCHS',
                ylabel='ERROR',
                ylimit=ylim)
    img_path = os.path.join(
        self._images_dirname,
        'train_test_loss_per_sim'+se.get_name().replace(' ', '')+'.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_mixing(self, se, simulation_num=0):
    fig = se._plot_mixing(simulation_num)

    img_path = os.path.join(self._images_dirname, se.get_name().replace(' ', '') + 'mixing.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_diffusion(self, se, simulation_num=0):
    fig = se._plot_diffusion(simulation_num)

    img_path = os.path.join(self._images_dirname, se.get_name().replace(' ', '') + 'diffusion.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_noise_level_histogram(self, se, replica_id=0, simulation_num=0):
    fig = se._plot_noise_level_histogram(replica_id, simulation_num)
    name = '_'.join(['hist', str(simulation_num), str(replica_id)])
    name = se.get_name().replace(' ', '') + name + '.png'
    
    img_path = os.path.join(self._images_dirname, name)

    plt.savefig(img_path, bbox_inches='tight')

    return img_path

  def _plot_loss_histogram_for_noise_level(self, se, noise_level=0, simulation_num=0):
    fig = se._plot_loss_histogram_for_noise_level(noise_level=noise_level,
                                                  simulation_num=simulation_num)

    levelstr = (str(noise_level) if not isinstance(noise_level, list)
                else '-'.join([str(x) for x in noise_level])) 
    name = '_'.join(['hist_loss_noise_levels',
                     str(simulation_num),
                     levelstr])
    name = se.get_name().replace(' ', '') + name + '.png'
    
    img_path = os.path.join(self._images_dirname, name)

    plt.savefig(img_path, bbox_inches='tight')

    return img_path
  def _create_specs_table(self, doc):
    """Generates summary table."""
    #original_names = "\n".join(self._original_names)
    for name in self._original_names:

      doc.append(name)
      doc.append(tex.LineBreak())
      doc.append(str(self._summ_ext[name].get_description()['noise_list']))
      doc.append(tex.LineBreak())
    doc.append(tex.LineBreak())

    col_names = ['Name',
                 'Accept',
                 'Mixing',
                 'Visit',
                 'Err',
                 'MoaErr',
                 'BurnIn',
                 'Swap',
                 'Sep',
                 'Coeff',
                 'DSize',
                 'LR',
                 'Batch',
                 '#params']

    table_spec = "|@{}l@{}".join(['' for i in range(len(col_names) + 1)]) + '|'

    tabular = tex.Tabular(table_spec,
                          pos=self._position,
                          booktabs=False,
                          row_height=0.1,)

    with doc.create(tabular) as table:
      table.add_hline()
      table.add_row(col_names)
      table.add_hline()

      for summ_ext in self._summ_ext:
        vals_ = {n:[] for n in col_names}
        se = self._summ_ext[summ_ext]
        desc = se.get_description()

        vals_['Accept'].append("{0:.3f}".format(se.get_accept_ratio()))
        vals_['Mixing'].append("{0:.3f}".format(se.get_mix_ratio()))
        vals_['Visit'].append("{0:.3f}".format(se.get_visit_ratio()))
        sep, err, std = se.get_sep_ratio_vs_min_error()
        vals_['Err'].append("{0:.5f}".format(err))
        if 'moa' == desc['mode']:
          vals_['MoaErr'].append("{0:.3f}".format(se.get_moa_min_err()))
        else:
          vals_['MoaErr'].append('NaN')
        vals_['BurnIn'].append(str(desc['burn_in_period']))
        vals_['Name'].append(se.get_name())
        vals_['Swap'].append(str(desc['swap_step']))
        vals_['Sep'].append(desc['separation_ratio'])
        vals_['Coeff'].append(desc['proba_coeff'])
        vals_['LR'].append(desc['learning_rate'])
        vals_['Batch'].append(desc['batch_size'])
        try:
          train_data_size = s_utils.get_value_from_name(se._original_name, 'train_data_size')
        except IndexError:
          train_data_size = 'unknown'
        vals_['DSize'].append(train_data_size)
        vals_['#params'].append(desc['n_params'])
        for k in vals_:
          if k != 'Coeff':
            vals_[k] = list(set(vals_[k]))
          else:
            try:
              vals_[k] = list(set(vals_[k]))
            except TypeError:
              vals_[k] = [desc['proba_coeff'][0]]

        row = []
        for col_name in col_names:
          if len(vals_[col_name]) == 1:
            row.append(str(vals_[col_name][0]))
          else:
            row.append(' ')

        table.add_row(row)
        table.add_hline()

class SummaryExtractor:

  def __init__(self, name, include_moa=True):
    dirname = os.path.abspath(os.path.dirname(__file__))
    self._name = name
    self._dirname = os.path.join(dirname, 'summaries', name)
    filenames = sorted([f for f in os.listdir(self._dirname) if 'summary' in f],
                       key=lambda x: int(x.split('_')[1].split('.')[0]))
    
    description_path = os.path.join(self._dirname, 'description.json')

    self._summaries = []
    self._n_simulations = len(filenames)
    self._include_moa = include_moa
    for f in filenames:
      filepath = os.path.join(self._dirname, f)
      try:
        with open(filepath, 'rb', os.O_NONBLOCK) as fo:
          self._summaries.append(pickle.load(fo))
      except EOFError:
        print(f)
        print(filepath)
        raise
    with open(description_path, 'r') as fo:
      self._description = json.load(fo)

    self._vals = {
        'accept_ratio': None,
        'mix_ratio': None,
        'visit_ratio': None,
        'accept_ratio_err': None,
        'visit_ratio_err': None,
        'avg_min_error': None,
        'avg_min_error_err': None,
        'avg_diff_for_min_error': None,
        'avg_diff_for_min_error_err': None,
        'avg_steps_for_min_error': None, # steps == epochs
        'avg_steps_for_min_error_err': None,
        'avg_err_differ': None,
        'avg_err_differ_err':None,
        'avg_err_final_differ':None,
        'avg_err_final_differ_err':None,
        '__debug__visit_raw':[],
        '__debug__err_differ': None,

    }

    self._n_replicas = self.get_description()['n_replicas']
    self._colors = plt.rcParams['axes.prop_cycle'].by_key()['color']
    self._moa_color = 'blue'

  def get_name(self):
    return self._name

  def get_sep_ratio_vs_final_err_differ(self):
    """Returns final difference between test-train error."""

    if self._vals['avg_err_final_differ'] is None:
      _ = self.get_sep_ratio_vs_err_differ()

    err_differ = self._vals['avg_err_final_differ']
    err_differ_std = self._vals['avg_err_final_differ_err']
    sep = self.get_description()['separation_ratio']

    return sep, err_differ, err_differ_std

  def get_sep_ratio_vs_err_differ(self):
    """Returns differences between test-train error.

    Differences are calculated:
      `min(test error) - train error[argmin(test_error)]`
    and returned averages over all simulations.
    """

    sep = self.get_description()['separation_ratio']

    if self._vals['avg_err_differ'] is not None:
      err_differ = self._vals['avg_err_differ']
      err_differ_std = self._vals['avg_err_differ_err']
      return sep, err_differ, err_differ_std
    err_differs = []
    err_final_differs = []
    reps = {i:[]
            for i in range(self._n_replicas)}

    reps_final = {i:[]
                  for i in range(self._n_replicas)}

    for s in range(self._n_simulations):
      for r in range(self._n_replicas):
        test_x, test_y = self.get_summary('test_error',
                                          replica_id=r,
                                          simulation_num=s)
        train_x, train_y = self.get_summary('train_error',
                                            replica_id=r,
                                            simulation_num=s)
        _, test_steps = self.get_summary('test_steps',
                                          replica_id=r,
                                          simulation_num=s)
        _, train_steps = self.get_summary('train_steps',
                                           replica_id=r,
                                           simulation_num=s)

        idx_test = np.argmin(test_y)
        try:
          idx_train = _find_nearest_idx(train_steps, test_steps[idx_test])
        except IndexError:
          idx_train = 0
        differ = test_y[idx_test] - train_y[idx_train]
        reps[r].append(differ)
        err_differs.append(differ)

        idx_test = len(test_y) - 1
        differ = test_y[idx_test] - np.mean(train_y[-s_utils.TRAIN_FREQ:])
        reps_final[r].append(differ)
        err_final_differs.append(differ)

    result = {i:0 for i in range(self._n_replicas)}
    for r in range(self._n_replicas):
      result[r] = np.mean(reps[r])
    self._vals['__debug__err_differ'] = result

    err_differ = np.mean(err_differs)
    err_differ_std = np.std(err_differs)

    self._vals['avg_err_differ'] = err_differ
    self._vals['avg_err_differ_err'] = err_differ_std
    self._vals['avg_err_final_differ'] = np.mean(err_final_differs)
    self._vals['avg_err_final_differ_err'] = np.std(err_final_differs)

    return sep, err_differ, err_differ_std

  def get_diffusion_vs_min_error(self):
    """Returns a min loss and diffusion value to achieve this min loss."""

    if self._vals['avg_min_error'] is None:
      losses = []
      diffs = []
      steps = []
      replicas = []

      for s in range(self._n_simulations):
        candidate_losses = []
        candidate_diffs = []
        candidate_steps = []

        for r in range(self._n_replicas):
          x_loss, y_loss = self.get_summary('test_error', replica_id=r,
                                            simulation_num=s)
          x_diff, y_diff = self.get_summary('diffusion', replica_id=r,
                                            simulation_num=s)
          y_loss = np.asarray(y_loss)
          loss_idx = y_loss.argmin()
          diff_idx = _find_nearest_idx(x_diff, x_loss[loss_idx])
          candidate_losses.append(y_loss[loss_idx])
          candidate_diffs.append(y_diff[diff_idx])
          candidate_steps.append(x_loss[loss_idx])

        self._vals['replica_id_min_err_sim_' + str(s)] = np.argmin(candidate_losses)

        idx = np.argmin(np.asarray(candidate_losses))
        losses.append(candidate_losses[idx])
        diffs.append(candidate_diffs[idx])
        steps.append(candidate_steps[idx])
        replicas.append(idx)

      loss_val = np.mean(losses)
      loss_err = np.std(losses)
      diff_val = np.mean(diffs)
      diff_err = np.std(diffs)
      step_val = np.mean(steps)
      step_err = np.std(steps)

      self._vals['avg_min_error'] = loss_val
      self._vals['avg_min_error_err'] = loss_err
      self._vals['avg_diff_for_min_error'] = diff_val
      self._vals['avg_diff_for_min_error_err'] = diff_err
      self._vals['avg_steps_for_min_error'] = step_val
      self._vals['avg_steps_for_min_error_err'] = step_err


    else:
      loss_val = self._vals['avg_min_error']
      loss_err = self._vals['avg_min_error_err']
      diff_val = self._vals['avg_diff_for_min_error']
      diff_err = self._vals['avg_diff_for_min_error_err']

    sep = self.get_description()['separation_ratio']
    return diff_val, diff_err, loss_val, loss_err, sep

  def get_n_steps_vs_min_error(self):
    """Returns a min error and number of steps to achieve this min loss."""
    if self._vals['avg_min_error'] is None:
      _ = self.get_diffusion_vs_min_error()

    loss_val = self._vals['avg_min_error']
    loss_err = self._vals['avg_min_error_err']
    step_val = self._vals['avg_steps_for_min_error']
    step_err = self._vals['avg_steps_for_min_error_err']
    sep = self.get_description()['separation_ratio']

    return step_val, step_err, loss_val, loss_err, sep

  def get_sep_ratio_vs_min_error(self):
    if self._vals['avg_min_error'] is None:
      _ = self.get_diffusion_vs_min_error()

    loss_val = self._vals['avg_min_error']
    loss_err = self._vals['avg_min_error_err']
    sep = self.get_description()['separation_ratio']

    return sep, loss_val, loss_err

  def get_sep_ratio_vs_accept_ratio(self):
    """Returns a tuple (`sep_ratio`, `accept_ratio`, `stddev`)."""

    sep = self.get_description()['separation_ratio']
    acc = self.get_accept_ratio()
    stddev = self._vals['accept_ratio_err']

    return sep, acc, stddev

  def get_sep_ratio_vs_mix_ratio(self):
    """Returns a tuple (`sep_ratio`, `mix_ratio`, `stddev`)."""
    sep = self.get_description()['separation_ratio']
    mix = self.get_mix_ratio()
    stddev = self._vals['mix_ratio_err']

    return sep, mix, stddev

  def get_sep_ratio_vs_visit_ratio(self):
    """Returns a tuple (`sep_ratio`, `visit_ratio`, `stddev`)."""

    sep = self.get_description()['separation_ratio']
    visit = self.get_visit_ratio()
    stddev = self._vals['visit_ratio_err']

    return sep, visit, stddev

  def show_report(self, simulation_num=0, sample_every=2, print_stats=True):
    """Shows the report of the simulation with plots."""
    if print_stats:
      sep, acc, stddev = self.get_sep_ratio_vs_accept_ratio()
      print('Accept Ratio:', acc, '+/-', stddev)

      sep, visit, stddev = self.get_sep_ratio_vs_visit_ratio()
      print('Visit Ratio:', visit, '+/-', stddev)

      sep, mix, stddev = self.get_sep_ratio_vs_mix_ratio()
      print('Mixing Ratio:', mix, '+/-', stddev)

      sep, loss_val, loss_err = self.get_sep_ratio_vs_min_error()
      _ = self.get_sep_ratio_vs_min_error()
      min_rid = self._vals['replica_id_min_err_sim_' + str(simulation_num)]
      print('Min Error value:', loss_val, '+/-', loss_err, 'for replica', min_rid)
      test_errs, valid_errs, train_errs = [],  [], []
      for r in range(self.get_description()['n_replicas']):
        x, y = self.get_summary('test_error', simulation_num=simulation_num, replica_id=r)
        test_errs.append((min(y), x[np.argmin(y)], r))
        x, y = self.get_summary('train_error', simulation_num=simulation_num, replica_id=r)
        train_errs.append((min(y), x[np.argmin(y)], r))
        x, y = self.get_summary('validation_error', simulation_num=simulation_num, replica_id=r)
        valid_errs.append((min(y), x[np.argmin(y)], r))
      zipped = zip(test_errs, valid_errs, train_errs)
      combined = [list(x) for x in zip(*sorted(zipped, key=lambda pair: pair[0][0]))]
      test_errs, valid_errs, train_errs = combined
      for i in range(self.get_description()['n_replicas']):
        buff = '[rid:{0}]|[test:{1:.5f} at {2}]|[valid:{3:.5f} at {4}]|[train:{5:.5f} at {6}]'.format(
            test_errs[i][-1], test_errs[i][0], int(test_errs[i][1]),
            valid_errs[i][0], int(valid_errs[i][1]),
            train_errs[i][0], int(train_errs[i][1]))
        print(buff)

      print('Min Valid Error value:', min(self.get_summary('validation_error')[1]))
      if ('mode' in self.get_description()
          and self.get_description()['mode'] is not None
          and 'moa' in self.get_description()['mode'].lower()):
        print('MOA Min Error value:', self.get_moa_min_err())

      sep, err_differ, err_differ_std = self.get_sep_ratio_vs_err_differ()
      print('Average Overfitting:',
            err_differ,
            '+/-',
            err_differ_std)

    print()
    _ = self._plot_loss(summ_name='test_loss',
                        simulation_num=simulation_num,
                        sample_every=sample_every,
                        include_moa=self._include_moa)
    _ = self._plot_loss(summ_name='train_loss',
                        simulation_num=simulation_num,
                        sample_every=sample_every,
                        include_moa=self._include_moa)
    _ = self._plot_error(summ_name='test_error',
                         simulation_num=simulation_num,
                         sample_every=sample_every,
                         include_moa=self._include_moa,
                         ylim=(0, 0.2))
    _ = self._plot_error(summ_name='validation_error',
                         simulation_num=simulation_num,
                         sample_every=sample_every,
                         include_moa=self._include_moa)
    _ = self._plot_moa_weights(simulation_num=simulation_num)
    _ = self._plot_test_err_vs_noise_level_vs_epochs(simulation_num=simulation_num)
    _ = self._plot_diffusion_vs_min_error(simulation_num=simulation_num,
                                          sample_every=sample_every)
    _ = self._plot_diffusion_vs_min_loss(simulation_num=simulation_num,
                                         sample_every=sample_every)
    _ = self._plot_train_test_error_gap(simulation_num=simulation_num,
                                        sample_every=sample_every)
    _ = self._plot_train_test_loss_gap(simulation_num=simulation_num,
                                       sample_every=sample_every)

    _ = self._plot_error(summ_name='train_error',
                         simulation_num=simulation_num,
                         sample_every=sample_every)
    _ = self._plot_diffusion(simulation_num=simulation_num)
    _ = self._plot_mixing(simulation_num=simulation_num)
    _ = self._plot_noise_level_histogram(simulation_num=simulation_num)
    '''
    _ = self._plot_grads(simulation_num=simulation_num,
                         sample_every=sample_every)
    _ = self._plot_norms(simulation_num=simulation_num)
    '''
  
  def get_accept_ratio(self):
    accepts = []
    if self._vals['accept_ratio'] is None:
      for s in range(self._n_simulations):
        for r in range(self._n_replicas):
          x, y = self.get_summary('accepts', replica_id=r, simulation_num=s)
          accepts.append(np.mean(y))
      self._vals['accept_ratio'] = np.mean(accepts)
      self._vals['accept_ratio_err'] = np.std(accepts)

    return self._vals['accept_ratio']

  def get_mix_ratio(self):
    if self._vals['mix_ratio'] is None:
      keys = [float("{0:.8f}".format(b))
              for b in self.get_description()['noise_list']]

      def _get_key(key):
        return keys[int(np.argmin([abs(k-key) for k in keys]))]

      mixing = {i:[] for i in range(self._n_replicas)}
      visiting = {i:[] for i in range(self._n_replicas)}
      travel_times = []
      for s in range(self._n_simulations):

        for r in range(self._n_replicas):
          x, y = self.get_summary('noise_values', replica_id=r, simulation_num=s)
          steps = self.get_summary('train_steps', replica_id=r, simulation_num=s)[1]
          #steps = sorted(list(set(steps)))

          reps = {k:0 for k in keys}

          for i in range(len(steps)):
            if steps[i] > self.get_description()['burn_in_period']:
              try:
                reps[_get_key(y[i])] += 1
              except IndexError:
                print(_get_key(y[i]))
                raise
          d = dict(replica_id=r,
                   simulation_num=s)
          d.update(reps)

          self._vals['__debug__visit_raw'].append(d)
          # histograms
          if 'histograms' not in self._vals:
            self._vals['histograms'] = {}

          if s not in self._vals['histograms']:
            self._vals['histograms'][s] = {}

          self._vals['histograms'][s][r] = reps

          visiting[r].append(np.mean([1 if reps[x]!=0 else 0 for x in reps]))
          mixing[r].append(1 if all(reps[x]!=0 for x in reps) else 0)

      mix_ratios = []
      visit_ratios = []

      for s in range(self._n_simulations):
        mix_ratio = np.mean([mixing[r][s] for r in range(self._n_replicas)])
        visit_ratio = np.mean([visiting[r][s] for r in range(self._n_replicas)])
        mix_ratios.append(mix_ratio)
        visit_ratios.append(visit_ratio)
      self._vals['mix_ratio'] = np.mean(mix_ratios)
      self._vals['visit_ratio'] = np.mean(visit_ratios)
      self._vals['mix_ratio_err'] = np.std(mix_ratios)
      self._vals['visit_ratio_err'] = np.std(visit_ratios)

    return self._vals['mix_ratio']

  def get_moa_min_err(self):
    if 'moa_min_err' not in self._vals:
      x, y = self.get_summary('moa_test_error', simulation_num=0)
      self._vals['moa_min_err'] = min(y)
    return self._vals['moa_min_err']

  def get_visit_ratio(self):
    if self._vals['visit_ratio'] is None:
      _ = self.get_mix_ratio()
    return self._vals['visit_ratio']

  def get_summary(self, summ_name, replica_id=0, simulation_num=0):
    """Returns summary for `summ_name`.

    Args:
      `summ_name`: Summary name. For a list of summaries see
        `simulator.graph.summary.flush_summary()` function.
      `replica_id`: A integer representing replica id.
      `simulation_num`: A simulation from which to return the summary.

    Returns:
      A tuple `(x, y)` where `x` is a numpy array of epochs and `y` is
      a list of summary.

    Raises:
      `ValueError`: If `simulation_num` is not in valid range.
    """

    if simulation_num >= self._n_simulations:
      err_msg = ("No such simulation: "
                 + str(simulation_num))
      raise ValueError(err_msg)
    if 'steps' in summ_name:
      y = self._summaries[simulation_num][summ_name]
      y = sorted(list(set(y)))
    elif 'moa' in summ_name and 'weights' not in summ_name:
      y = self._summaries[simulation_num][summ_name] 
    else:
      y = self._summaries[simulation_num][summ_name][replica_id]
    n_epochs = self._summaries[simulation_num]['latest_epoch'] + 1
    try:
      x = np.linspace(start=0,
                      stop=n_epochs,
                      num=len(y))
    except TypeError:
      print(summ_name, y)
      raise
    return x, y

  def get_description(self):
    return self._description

  def _plot_moa_weights(self, simulation_num=0):
    fig, ax = plt.subplots()
    plot = Plot()
    for r in range(self._n_replicas):
      x, y = self.get_summary('moa_weights', replica_id=r, simulation_num=simulation_num)
      plot.plot(x, y, fig=fig, ax=ax, label='Replica ' + str(r))

    plot.legend(fig, ax, xlabel='EPOCHS', ylabel='MOA WEIGHTS')

  def _plot_loss(self, summ_name, simulation_num=0, sample_every=1, ylim=(0, 5), include_moa=False):
    fig, ax = plt.subplots()
    plot = Plot()
    if (include_moa
        and 'mode' in self.get_description()
        and self.get_description()['mode'] is not None
        and 'moa' in self.get_description()['mode'].lower()):

      if 'test' in summ_name:
        label = 'Test Loss (MOA)'
        linestyle = '-'
        summary_name = 'moa_test_loss'
      else:
        label = 'Train Loss (MOA)'
        linestyle = '--'
        summary_name = 'moa_train_loss'
      x, y = self.get_summary(summary_name, simulation_num=simulation_num)
      plot.plot(x, y, fig=fig, ax=ax, label=label, linewidth=1., linestyle=linestyle,
                color=self._moa_color)

    for r in range(self._n_replicas):
      if summ_name == 'test_loss':
        x, y = self.get_summary('test_loss', r, simulation_num)
        plot.plot(x, y, fig=fig, ax=ax, label='Test Loss (replica ' + str(r) + ')',
                  linewidth=1, color=self._colors[r])
        #x = x[::sample_every]
        #y = y[::sample_every]
      elif summ_name == 'train_loss':
        x1, y1 = self.get_summary('train_loss', r, simulation_num)
        #y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
        #y1 = y1[::sample_every]
        x1 = np.linspace(start=0, stop=x1[-1], num=len(y1))
        plot.plot(x1, y1, fig=fig, ax=ax, label='Train loss (replica ' + str(r) + ')',
                  linewidth=1, linestyle='--', splined_points_mult=None,
                  color=self._colors[r])

    plot.legend(fig, ax, title=summ_name.upper().replace('_', ' '),
                legend_title='Replica', xlabel='EPOCHS',
                ylabel='LOSS', ylimit=ylim)

  def _plot_error(self, summ_name, simulation_num=0, sample_every=1, ylim=(0, 1), include_moa=False):
    fig, ax = plt.subplots()
    plot = Plot()
    if (include_moa
        and 'mode' in self.get_description()
        and self.get_description()['mode'] is not None
        and 'moa' in self.get_description()['mode'].lower()):
      if 'test' in summ_name:
        label = 'Test Error (MOA)'
        linestyle = '-'
        summary_name = 'moa_test_error'
      else:
        label = 'Train Error (MOA)'
        linestyle = '--'
        summary_name = 'moa_train_error'
      x, y = self.get_summary(summary_name, simulation_num=simulation_num)
      plot.plot(x, y, fig=fig, ax=ax, label=label, linewidth=1., linestyle=linestyle,
                color=self._moa_color)
    for r in range(self._n_replicas):
      if 'test' in summ_name or 'validation' in summ_name:
        x, y = self.get_summary(summ_name, r, simulation_num)
        plot.plot(x, y, fig=fig, ax=ax, label='Test error (replica ' + str(r) + ')',
                  linewidth=1, color=self._colors[r])
        #x = x[::sample_every]
        #y = y[::sample_every]
      elif 'train' in summ_name:
        x1, y1 = self.get_summary(summ_name, r, simulation_num)
        #y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
        #y1 = y1[::sample_every]
        x1 = np.linspace(start=0, stop=x1[-1], num=len(y1))
        plot.plot(x1, y1, fig=fig, ax=ax, label='Train error (replica ' + str(r) + ')',
                  linewidth=1, linestyle='--', splined_points_mult=None,
                  color=self._colors[r])

    plot.legend(fig, ax, legend_title='Replica',
                title=summ_name.upper().replace('_', ' '),
                xlabel='EPOCHS', ylabel='0-1 ERROR', ylimit=ylim)

  def _plot_noise_level_histogram(self, replica_id=-1, simulation_num=0):

    if replica_id == -1:
      _ = self.get_sep_ratio_vs_min_error()
      replica_id = self._vals['replica_id_min_err_sim_' + str(simulation_num)]
    
    #print(sorted(list(histogram.items()), key=lambda x: x[0]))
    
    x, y = self.get_summary('noise_values',
                            replica_id=replica_id,
                            simulation_num=simulation_num)
    x, steps = self.get_summary('train_steps',
                                replica_id=replica_id,
                                simulation_num=simulation_num)

    y = [y[i] for i in range(len(y))
         if steps[i] > self.get_description()['burn_in_period']]

    plot = Plot()
    fig, ax = plt.subplots()
    binwidth = 1
    weights = np.ones_like(y)/float(len(y))
    ax.hist(y, rwidth=0.5, weights=weights)

    plot.legend(fig, ax, xlabel='Noise Level', ylabel='Visiting Ratio')

  def _plot_loss_histogram_for_noise_level(self,
                                           summ_name='validation_loss',
                                           noise_level=0,
                                           simulation_num=0,
                                           epsilon = 0.01,
                                           bins=60,
                                           burn_in_period=None,
                                           transformation=None,
                                           fitting_distribution=None):
    """Plots histogram of energy distributions.

    Args:
      summ_name: One of `validation/train/test_loss/error`.
      noise_level: Integer of list integers specifying a noise levels
        to plot.
      simulation_num: A number of simulation to plot.
      epsilon: Additional width that added on sides of the plot.
      bins: A number of bins for historgram.
      burn_in_period: A step (swap step) from which the energies are
        started to be taken into account.
      transformation: A function that takes values `x` energy,
        applies some mathematical transformation and returns resulted
        value. E.g. `def foo(x): return np.exp(x)`. Default is
        identity.
      fitting_distribution: A fitting function for
        `seaborn.distplot()` in addition to default KDE curve.
    """
    def identity(x): return x
    noise_list = sorted(self.get_description()['noise_list'])
    n_replicas = self.get_description()['n_replicas']
    if transformation is None:
      transform_foo = identity
    else:
      transform_foo = transformation
    

    noise_vals = {i:self.get_summary('noise_values', i, simulation_num)[1]
                  for i in range(n_replicas)}

    loss_vals = {i:self.get_summary(summ_name, i, simulation_num)[1]
                 for i in range(n_replicas)}

    _, steps = self.get_summary('_'.join([summ_name.split('_')[0], 'steps']),
                                replica_id=0,
                                simulation_num=simulation_num)

    if burn_in_period is None:
      if self.get_description()['burn_in_period'] == np.inf:
        burn_in_period = steps[len(steps)//4]
      else:
        burn_in_period = self.get_description()['burn_in_period']

    if not isinstance(noise_level, list):
      noise_levels = [noise_level]

    else:
      noise_levels = noise_level
    
    fig, ax = plt.subplots()
    plot = Plot()
    min_loss_val = 1000
    max_loss_val = -1
    means = []
    stddevs = []
    for noise_level in noise_levels:
      noise_level_loss = []
      for i in range(len(steps)):
        if steps[i] < burn_in_period:
          continue
        try:
          curr_noise_dict = {r:noise_vals[r][i] for r in range(n_replicas)}
        except:
          break

        beta = [curr_noise_dict[r] for r in range(n_replicas)]
        beta_rid = [(b, r) for r, b in enumerate(beta)]
        beta_rid.sort(key=lambda x: x[0])
        rid = beta_rid[noise_level][1]
        loss_val = transform_foo(loss_vals[rid][i])
        min_loss_val = min(loss_val, min_loss_val)
        max_loss_val = max(loss_val, max_loss_val)
        noise_level_loss.append(loss_val)

      

      means.append(np.mean(noise_level_loss))
      stddevs.append(np.std(noise_level_loss))
      label = 'Noise Level: ' + "{0:.3f}({1})".format(noise_list[noise_level], noise_level)
      '''
      Notes on arguments for `seaborn.distplot()`:
        * kde: kernel density estimation. Non-parametric way to
          to estimate the probability density function of
          a random variable. Definition:

      '''
      seaborn.distplot(noise_level_loss, kde=True,
        hist=True, norm_hist=True, bins=bins, hist_kws={'edgecolor':'black'},
        kde_kws={'linewidth':4},
        label=label, fit=fitting_distribution)

    mean = np.mean(means)
    stddev = np.mean(stddevs)
    xlimit = (min(min_loss_val, mean-2*stddev) - epsilon, max(max_loss_val, mean+2*stddev) + epsilon)
    xlabel='Energy Levels'
    if transformation is not None:
        foostr = inspect.getsource(transformation).replace('. Filename: ', ';') 
        xlabel = xlabel + '\nTransformation: ' + foostr     
    plot.legend(fig, ax, xlabel=xlabel, ylabel='Histogram',
        xlimit=xlimit)
    return fig

  def _plot_exchange_proba_hist(self, replica_id=-1, simulation_num=0, proba_coeff=None,
      isnormalized=True, bins=60, epsilon=1e-3):
    """Plots probability of chaging noise at swap step for `replica_id`."""

    def get_lower_and_upper_rids(rid, curr_noise_dict):
      beta = [curr_noise_dict[r] for r in range(n_replicas)]
      beta_rid = [(b, r) for r, b in enumerate(beta)]
      reverse = (True if noise_type in ['weight_noise', 'langevin'] else False)
      beta_rid.sort(key=lambda x: x[0], reverse=reverse)
      rid_level = [i for i in range(len(beta_rid)) if beta_rid[i][1] == rid][0]
      if rid_level == n_replicas - 1:
        hrid = -1
      else:
        hrid = beta_rid[rid_level+1][1]

      if rid_level == 0:
        lrid = -1
      else:
        lrid = beta_rid[rid_level-1][1]

      return lrid, hrid
    

    if replica_id == -1:
      _ = self.get_sep_ratio_vs_min_error()
      replica_id = self._vals['replica_id_min_err_sim_' + str(simulation_num)]


    noise_list = sorted(self.get_description()['noise_list'])
    n_replicas = self.get_description()['n_replicas']
    noise_type = self.get_description()['noise_type']
    if proba_coeff is None:
      proba_coeff = self.get_description()['proba_coeff']
    n_epochs = self.get_description()['n_epochs']

    rid = replica_id

    noise_vals = {i:self.get_summary('noise_values', i, simulation_num)[1]
                  for i in range(n_replicas)}

    loss_vals = {i:self.get_summary('validation_loss', i, simulation_num)[1]
                 for i in range(n_replicas)}

    tolower_probas = []
    tohigher_probas = []
    tostay_probas = []
    endidx = len(loss_vals[0])


    for step in range(endidx):
      try:
        curr_noise_dict = {r:noise_vals[r][step] for r in range(n_replicas)}
        curr_loss_dict = {r:loss_vals[r][step] for r in range(n_replicas)}
      except IndexError:
        break
        print('step:', step)
        print('noise:')
        for r, v in noise_vals.items():
          print('rid:', r, 'len:', len(v))
        print('loss:')
        for r, v in loss_vals.items():
          print('rid:', r, 'len:', len(v))
        raise
      lrid, hrid = get_lower_and_upper_rids(rid, curr_noise_dict)
      if lrid == -1:
        proba_lower = 0.0
        tolower_probas.append(proba_lower)
      else:
        li = curr_loss_dict[lrid]
        lj = curr_loss_dict[rid]
        bi = curr_noise_dict[lrid]
        bj = curr_noise_dict[rid]
        proba_lower = np.exp(proba_coeff*(li - lj)*(bi - bj))
        proba_lower = min(proba_lower, 1.0)
        if isnormalized:
          proba_lower *= (1/(n_replicas - 1))
        tolower_probas.append(proba_lower)

      if hrid == -1:
        proba_higher = 0.0
        tohigher_probas.append(proba_higher)
      else:
        li = curr_loss_dict[rid]
        lj = curr_loss_dict[hrid]
        bi = curr_noise_dict[rid]
        bj = curr_noise_dict[hrid]
        proba_higher = np.exp(proba_coeff*(li - lj)*(bi - bj))
        proba_higher = min(1.0, proba_higher)
        if isnormalized:
          proba_higher *= (1/(n_replicas-1))
        tohigher_probas.append(proba_higher)

      proba_stay = max(0.0, 1.0 - proba_lower - proba_higher)
      tostay_probas.append(proba_stay)

    fig, ax = plt.subplots()
    plot = Plot()

    x = np.linspace(0, n_epochs, len(tostay_probas))

    if epsilon is not None:
      tostay_probas = [x for x in tostay_probas if x >= epsilon]
      tohigher_probas = [x for x in tohigher_probas if x >= epsilon]
      tolower_probas = [x for x in tolower_probas if x >= epsilon]
    seaborn.distplot(tostay_probas, kde=True, hist=True, norm_hist=True,
                     bins=bins, hist_kws={'edgecolor':'black'},
                     kde_kws={'linewidth':4}, label='Next State is Current State')
    seaborn.distplot(tohigher_probas, kde=True, hist=True, norm_hist=True,
                     bins=bins, hist_kws={'edgecolor':'black'},
                     kde_kws={'linewidth':4}, label='Next State is Higher State')
    seaborn.distplot(tolower_probas, kde=True, hist=True, norm_hist=True,
                     bins=bins, hist_kws={'edgecolor':'black'},
                     kde_kws={'linewidth':4}, label='Next State is Lower State')


    plot.legend(fig, ax, xlabel='Probability', ylabel='Histogram', xlimit=(0, 1))
    '''
    if isnormalized:
      plot.plot(x, tostay_probas, fig=fig, ax=ax, label='NEXT_NOISE to CURR_NOISE')
    plot.plot(x, tohigher_probas, fig=fig, ax=ax, label='NEXT_NOISE to HIGHER_NOISE')
    plot.plot(x, tolower_probas, fig=fig, ax=ax, label='NEXT_NOISE to LOWER_NOISE')
    plot.legend(fig, ax, xlabel='EPOCHS', ylabel='PROBABILITY')
    '''
    return fig

  def _plot_test_err_vs_noise_level_vs_epochs(self, replica_id=-1, simulation_num=0):

    if replica_id == -1:
      _ = self.get_sep_ratio_vs_min_error()
      replica_id = self._vals['replica_id_min_err_sim_' + str(simulation_num)]

    x_noise, noise_vals = self.get_summary('noise_values',
                                            replica_id=replica_id,
                                            simulation_num=simulation_num)
    
    x_err, err_vals = self.get_summary('test_error',
                                       replica_id=replica_id,
                                       simulation_num=simulation_num)

    x_diff, diff = self.get_summary('diffusion',
                                    replica_id=replica_id,
                                    simulation_num=simulation_num)
    diff = np.asarray(diff)

    x_train_steps, train_steps = self.get_summary('train_steps',
                                                  replica_id=replica_id,
                                                  simulation_num=simulation_num)

    x_test_steps, test_steps = self.get_summary('test_steps',
                                                replica_id=replica_id,
                                                simulation_num=simulation_num)



    fig = plt.figure()
    fig.set_size_inches(18, 10)

    ax = fig.gca(projection='3d')

    epsilon = 0.005
    ax.plot(x_noise, noise_vals, np.zeros_like(noise_vals), linewidth=1, label='Noise Level')
    ax.plot(x_err, (max(noise_vals) + epsilon)*np.ones_like(err_vals), err_vals, linewidth=1, label='Error')
    ax.plot(x_diff, (max(noise_vals) + 5*epsilon)*np.ones_like(x_diff), diff/diff.max(), label='Diffusion')
    ax.set_zlabel('Error and Normalized Diffusion')
    plt.xlabel('Epochs')
    plt.ylabel('Noise Level')
    ax.view_init(20, 270)
    
    plt.ylim(min(noise_vals) - epsilon, max(noise_vals) + 6*epsilon)
    plt.legend()


  def _plot_norms(self, simulation_num=0):
    fig, ax = plt.subplots()
    plot = Plot()
    for r in range(self._n_replicas):
      x, y = self.get_summary('weight_norms', r, simulation_num)
      plot.plot(x, y, fig=fig, ax=ax, label='replica ' + str(r),
                linewidth=2)
    plot.legend(fig, ax, legend_title='Replica',
                xlabel='EPOCHS', ylabel='WEIGHT L2 NORM')
    return fig

  def _plot_diffusion(self, simulation_num=0):
    fig, ax = plt.subplots()
    plot = Plot()
    for r in range(self._n_replicas):

      x, y = self.get_summary('diffusion', r, simulation_num)
      plot.plot(x, y, fig=fig, ax=ax, label='replica ' + str(r),
                linewidth=2)

    plot.legend(fig, ax, legend_title='Replica',
                xlabel='EPOCHS', ylabel='DIFFUSION')
    return fig

  def _plot_diffusion_vs_min_error(self, replica_id=0,
                                   simulation_num=0, sample_every=1,
                                   ylim=(0, 1)):

    _ = self.get_sep_ratio_vs_min_error()
    min_rid = self._vals['replica_id_min_err_sim_' + str(simulation_num)]
    x_test, y_test = self.get_summary('test_error',
                                      replica_id=min_rid,
                                      simulation_num=simulation_num)
    x_train, y_train = self.get_summary('train_error',
                                        replica_id=min_rid,
                                        simulation_num=simulation_num)
    x_diff, y_diff = self.get_summary('diffusion',
                                      replica_id=min_rid,
                                      simulation_num=simulation_num)
    #_test, y_test = x_test[::sample_every], y_test[::sample_every]
    #x_train, y_train = x_train[::sample_every], y_train[::sample_every]
    #x_diff, y_diff = x_diff[::sample_every], y_diff[::sample_every]
    #return x_test, y_test, x_train, y_train, x_diff, y_diff

    result = dict(train=[], test=[], diff=[])

    sorted_ = sorted([('train', y_train, x_train, len(y_train)),
                      ('test', y_test, x_test, len(y_test)),
                      ('diff', y_diff, x_diff, len(y_diff))], key=lambda x: x[3])

    for i in range(sorted_[0][3]):
      result[sorted_[0][0]].append(sorted_[0][1][i])
      result[sorted_[1][0]].append(sorted_[1][1][_find_nearest_idx(sorted_[1][2], sorted_[0][2][i])])
      result[sorted_[2][0]].append(sorted_[2][1][_find_nearest_idx(sorted_[2][2], sorted_[0][2][i])])

    x_test = np.linspace(start=0, stop=self.get_description()['n_epochs'], num=len(result['test']))
    x_train = np.linspace(start=0, stop=self.get_description()['n_epochs'], num=len(result['train']))
    x_diff = np.linspace(start=0, stop=self.get_description()['n_epochs'], num=len(result['diff']))

    fig = plt.figure()
    fig.set_size_inches(18, 10)

    ax = fig.gca(projection='3d')
    
    #ax.plot(x_test, np.asarray(result['test']), np.asarray(result['diff']),
    #        label='Test Error', color=self._colors[0], linewidth=1.2)
    ax.plot(x_test, np.asarray(result['test']), np.zeros(len(result['test'])),
            color=self._colors[0], linewidth=1, label='Test Error')
    ax.plot(x_test, ylim[1]*np.ones(len(result['test'])), result['diff'],
            color=self._colors[0], linewidth=1)

    #ax.plot(x_train, np.asarray(result['train']), np.asarray(result['diff']),
    #        color=self._colors[1], linestyle='--', label='Train Error', linewidth=1.2)
    ax.plot(x_train, np.asanyarray(result['train']), np.zeros(len(result['train'])),
            color=self._colors[1], linestyle='--', linewidth=1, label='Train Error')

    ax.view_init(20, 270)

    xlabel = ('EPOCHS\n'
              + 'Train-Diffusion Corr: '
              + "{0:.2f}".format(pearsonr(y_train, y_diff)[0])
              + ', Test-Diffusion Corr: '
              + "{0:.2f}".format(pearsonr(result['test'], result['diff'])[0]))

    plt.xlabel(xlabel, labelpad=20)
    plt.ylabel('Error')
    ax.set_zlabel('Diffusion')
    plt.legend()
    plt.ylim(ylim[0], ylim[1]) 
    #loc = plticker.MultipleLocator(base=len(result[sorted_[0][0]])//20)
    #ax.xaxis.set_major_locator(loc)
    xticks = [int(x/10)*10 for x in np.linspace(0, self.get_description()['n_epochs'], 20)]
    ax.set_xticks(xticks)

  def _plot_diffusion_vs_min_loss(self, replica_id=0, simulation_num=0, sample_every=1, ylim=(0, 5)):

    _ = self.get_sep_ratio_vs_min_error()
    min_rid = self._vals['replica_id_min_err_sim_' + str(simulation_num)]
    x_test, y_test = self.get_summary('test_loss',
                                      replica_id=min_rid,
                                      simulation_num=simulation_num)
    x_train, y_train = self.get_summary('train_loss',
                                        replica_id=min_rid,
                                        simulation_num=simulation_num)
    x_diff, y_diff = self.get_summary('diffusion',
                                      replica_id=min_rid,
                                      simulation_num=simulation_num)
    #x_test, y_test = x_test[::sample_every], y_test[::sample_every]
    #x_train, y_train = x_train[::sample_every], y_train[::sample_every]
    #x_diff, y_diff = x_diff[::sample_every], y_diff[::sample_every]
    #return x_test, y_test, x_train, y_train, x_diff, y_diff

    result = dict(train=[], test=[], diff=[])

    sorted_ = sorted([('train', y_train, x_train, len(y_train)),
                      ('test', y_test, x_test, len(y_test)),
                      ('diff', y_diff, x_diff, len(y_diff))], key=lambda x: x[3])

    for i in range(sorted_[0][3]):
      result[sorted_[0][0]].append(sorted_[0][1][i])
      result[sorted_[1][0]].append(sorted_[1][1][_find_nearest_idx(sorted_[1][2], sorted_[0][2][i])])
      result[sorted_[2][0]].append(sorted_[2][1][_find_nearest_idx(sorted_[2][2], sorted_[0][2][i])])

    x_test = np.linspace(start=0, stop=self.get_description()['n_epochs'], num=len(result['test']))
    x_train = np.linspace(start=0, stop=self.get_description()['n_epochs'], num=len(result['train']))
    x_diff = np.linspace(start=0, stop=self.get_description()['n_epochs'], num=len(result['diff']))


    fig = plt.figure()
    fig.set_size_inches(18, 10)

    ax = fig.gca(projection='3d')
    
    #ax.plot(x_test, np.asarray(result['test']), np.asarray(result['diff']),
    #        label='Test Loss', color=self._colors[0], linewidth=1.2)
    ax.plot(x_test, np.asarray(result['test']), np.zeros(len(result['test'])),
            color=self._colors[0], linewidth=1, label='Test Loss')
    ax.plot(x_test, ylim[1]*np.ones(len(result['test'])), result['diff'],
            color=self._colors[0], linewidth=1,)

    #ax.plot(x_train, np.asarray(result['train']), np.asarray(result['diff']),
    #        color=self._colors[1], linestyle='--', label='Train Loss', linewidth=1.2)
    ax.plot(x_train, np.asanyarray(result['train']), np.zeros(len(result['train'])),
            color=self._colors[1], linestyle='--', linewidth=1, label='Train Loss')

    ax.view_init(20, 270)
    
    xlabel = ('EPOCHS\n'
              + 'Train-Diffusion Corr: '
              + "{0:.2f}".format(pearsonr(y_train, y_diff)[0])
              + ', Test-Diffusion Corr: '
              + "{0:.2f}".format(pearsonr(result['test'], result['diff'])[0]))

    plt.xlabel(xlabel, labelpad=20)
    plt.ylabel('Loss')
    ax.set_zlabel('Diffusion')
    plt.legend()
    plt.ylim(ylim[0], ylim[1])
    xticks = [int(x/10)*10 for x in np.linspace(0, self.get_description()['n_epochs'], 20)]
    ax.set_xticks(xticks)
  
  def _data_for_train_test_error_gap(self, simulation_num=0, sample_every=1, ylim=(0, 1)):
    _ = self.get_sep_ratio_vs_min_error()
    min_rid = self._vals['replica_id_min_err_sim_' + str(simulation_num)]
    x_test, y_test = self.get_summary('test_error',
                                      replica_id=min_rid,
                                      simulation_num=simulation_num)
    x_train, y_train = self.get_summary('train_error',
                                        replica_id=min_rid,
                                        simulation_num=simulation_num)
    x_diff, y_diff = self.get_summary('diffusion',
                                      replica_id=min_rid,
                                      simulation_num=simulation_num)
    #x_test, y_test = x_test[::sample_every], y_test[::sample_every]
    #x_train, y_train = x_train[::sample_every], y_train[::sample_every]
    #x_diff, y_diff = x_diff[::sample_every], y_diff[::sample_every]
    #return x_test, y_test, x_train, y_train, x_diff, y_diff

    result = dict(train=[], test=[], diff=[])

    sorted_ = sorted([('train', y_train, x_train, len(y_train)),
                      ('test', y_test, x_test, len(y_test)),
                      ('diff', y_diff, x_diff, len(y_diff))], key=lambda x: x[3])

    for i in range(sorted_[0][3]):
      result[sorted_[0][0]].append(sorted_[0][1][i])
      result[sorted_[1][0]].append(sorted_[1][1][_find_nearest_idx(sorted_[1][2], sorted_[0][2][i])])
      result[sorted_[2][0]].append(sorted_[2][1][_find_nearest_idx(sorted_[2][2], sorted_[0][2][i])])

    x_gap = np.linspace(start=0, stop=self.get_description()['n_epochs'], num=len(result['test']))
    #x_train = np.linspace(start=0, stop=self.get_description()['n_epochs'], num=len(result['train']))
    x_diff = np.linspace(start=0, stop=self.get_description()['n_epochs'], num=len(result['diff']))
    y_gap = np.asarray(result['test']) - np.asarray(result['train'])

    return x_gap, y_gap, x_diff, result

  def _plot_train_test_error_gap(self, simulation_num=0, sample_every=1, ylim=(0, 1)):

    
    x_gap, y_gap, x_diff, result = self._data_for_train_test_error_gap(
        simulation_num=simulation_num, sample_every=sample_every, ylim=ylim)
    fig = plt.figure()
    fig.set_size_inches(18, 10)

    ax = fig.gca(projection='3d')
    
    #ax.plot(x_gap, y_gap, np.asarray(result['diff']),
    #        label='Test-Train Error Gap', color=self._colors[0], linewidth=1.2)
    ax.plot(x_gap, y_gap, np.zeros(len(result['test'])),
            color=self._colors[0], linewidth=1.2, label='Test-Train Error Gap')
    ax.plot(x_gap, ylim[1]*np.ones(len(result['test'])), result['diff'],
            color=self._colors[0], linewidth=1.2,)

    ax.view_init(20, 270)
    
    xlabel = ('EPOCHS\n'
              + 'Gap-Diffusion Corr: '
              + "{0:.2f}".format(pearsonr(y_gap, result['diff'])[0]))

    plt.xlabel(xlabel, labelpad=20)
    plt.ylabel('Error Gap')
    plt.ylim(min(0, min(y_gap)), ylim[1])
    ax.set_zlabel('Diffusion')
    plt.legend()

  def _data_for_train_test_loss_gap(self, simulation_num=0, sample_every=1, ylim=(0, 5)):
    _ = self.get_sep_ratio_vs_min_error()
    min_rid = self._vals['replica_id_min_err_sim_' + str(simulation_num)]
    x_test, y_test = self.get_summary('test_loss',
                                      replica_id=min_rid,
                                      simulation_num=simulation_num)
    x_train, y_train = self.get_summary('train_loss',
                                        replica_id=min_rid,
                                        simulation_num=simulation_num)
    x_diff, y_diff = self.get_summary('diffusion',
                                      replica_id=min_rid,
                                      simulation_num=simulation_num)
    #x_test, y_test = x_test[::sample_every], y_test[::sample_every]
    #x_train, y_train = x_train[::sample_every], y_train[::sample_every]
    #x_diff, y_diff = x_diff[::sample_every], y_diff[::sample_every]
    #return x_test, y_test, x_train, y_train, x_diff, y_diff

    result = dict(train=[], test=[], diff=[])

    sorted_ = sorted([('train', y_train, x_train, len(y_train)),
                      ('test', y_test, x_test, len(y_test)),
                      ('diff', y_diff, x_diff, len(y_diff))], key=lambda x: x[3])

    for i in range(sorted_[0][3]):
      result[sorted_[0][0]].append(sorted_[0][1][i])
      result[sorted_[1][0]].append(sorted_[1][1][_find_nearest_idx(sorted_[1][2], sorted_[0][2][i])])
      result[sorted_[2][0]].append(sorted_[2][1][_find_nearest_idx(sorted_[2][2], sorted_[0][2][i])])

    x_gap = np.linspace(start=0, stop=self.get_description()['n_epochs'], num=len(result['test']))
    #x_train = np.linspace(start=0, stop=self.get_description()['n_epochs'], num=len(result['train']))
    x_diff = np.linspace(start=0, stop=self.get_description()['n_epochs'], num=len(result['diff']))
    y_gap = np.asarray(result['test']) - np.asarray(result['train'])
    return x_gap, y_gap, x_diff, result
  
  def _plot_train_test_loss_gap(self, simulation_num=0, sample_every=1, ylim=(0, 5)):

    x_gap, y_gap, x_diff, result = self._data_for_train_test_loss_gap(
        simulation_num=simulation_num, sample_every=sample_every, ylim=ylim)

    fig = plt.figure()
    fig.set_size_inches(18, 10)

    ax = fig.gca(projection='3d')
    
    #ax.plot(x_gap, y_gap, np.asarray(result['diff']),
    #        label='Test-Train Loss Gap', color=self._colors[0], linewidth=1.2)
    ax.plot(x_gap, y_gap, np.zeros(len(result['test'])),
            color=self._colors[0], linewidth=1.2, label='Test-Train Loss Gap')
    ax.plot(x_gap, ylim[1]*np.ones(len(result['test'])), result['diff'],
            color=self._colors[0], linewidth=1.2,)

    ax.view_init(20, 270)
    xlabel = ('EPOCHS\n'
              + 'Gap-Diffusion Corr: '
              + "{0:.2f}".format(pearsonr(y_gap, result['diff'])[0]))

    plt.xlabel(xlabel, labelpad=20)
    plt.ylabel('Loss Gap')
    plt.ylim(min(ylim[0], min(y_gap)), ylim[1])
    ax.set_zlabel('Diffusion')
    plt.legend()

  def _plot_grads(self, simulation_num=0, sample_every=1):
    fig, ax = plt.subplots()
    plot = Plot()
    for r in range(self._n_replicas):
      x, y = self.get_summary('grad_norms', r, simulation_num)
      #x, y = x[::sample_every], y[::sample_every]
      plot.plot(x, y, fig=fig, ax=ax, label='replica ' + str(r),
                linewidth=1.5)

    plot.legend(fig, ax, legend_title='Replica',
                xlabel='EPOCHS', ylabel='GRADIENT L2 NORM', log_y=5)

    return fig

  def _plot_mixing(self, simulation_num=0):
    def _get_key(key):
      keys = [float("{0:.5f}".format(b))
              for b in self.get_description()['noise_list']]
      return keys[int(np.argmin([abs(k-key) for k in keys]))]

    fig, ax = plt.subplots()
    plot = Plot()
    noise_list = self.get_description()['noise_list']

    key_map = {_get_key(key):i for i, key in enumerate(noise_list)}
    for r in range(self._n_replicas):
      x, y = self.get_summary('noise_values', replica_id=r, simulation_num=simulation_num)

      y_new = [key_map[_get_key(i)] for i in y]
      plot.plot(x, y_new, fig=fig, ax=ax, label='replica ' + str(r),
                linewidth=2)
    yticks_names = [float("{0:.5f}".format(b)) for b in noise_list]

    plt.gca().set_yticklabels(['0'] + yticks_names)
    plot.legend(fig, ax, legend_title='Replica',
                xlabel='EPOCHS', ylabel='NOISE LEVEL')
    return fig

  ##################### Experimental #####################

  def _plot_bestsofar(self, summ_name='validation_loss', simulation_num=0):

    losses = {r: self.get_summary(summ_name, replica_id=r, simulation_num=simulation_num)[1]
              for r in range(self._n_replicas)}

    bestsofar = {r:[losses[r][0]] for r in range(self._n_replicas)}

    for i in range(1, len(losses[0])):

      _ = [bestsofar[r].append(min(bestsofar[r][-1], losses[r][i])) 
           for r in range(self._n_replicas)]

    fig, ax = plt.subplots()
    plot = Plot()
    x = np.linspace(1, self.get_description()['n_epochs'], len(bestsofar[0]))

    _ = [plot.plot(x, bestsofar[r], fig=fig, ax=ax, label='replica-' + str(r))
         for r in range(self._n_replicas)]
    plot.legend(fig, ax, xlabel='EPOCHS', ylabel=summ_name.replace('_', '-'))
    return fig

  def _proba_if_coeff_was(self, coeff=None, simulation_num=0):
    debug = self._summaries[simulation_num]['debug']
    pairs = self._get_swap_pairs(simulation_num)
    coeff = coeff or self.get_description()['proba_coeff']
    noise_list = self.get_description()['noise_list']
    betas = [1/n for n in noise_list] 
    if not isinstance(coeff, list):
      coeff = [coeff for _ in range(self.get_description()['n_replicas'] - 1)]
    pairs_coeffs = {p: c for p, c in zip(pairs, coeff)}
    for i, p in enumerate(pairs):
      probas = []
      exp_args = debug['exp_args'][p]
      for exp_arg in exp_args:
        proba = min(1, np.exp(pairs_coeffs[p]*exp_arg))
        probas.append(proba)

      print(i, p, '--->', np.mean(probas), np.std(probas))

  def _get_swap_pairs(self, simulation_num=0):
    """Returns a tuples of adjacent temperatures (temp_i, temp_i+1)."""
    debug = self._summaries[simulation_num]['debug']
    return list(sorted(debug['exp_args'].keys(), reverse=True))

def _find_nearest_idx(array, value):
  """Returns the index of the closest to the `value` value in `array`."""
  array = np.asarray(array)
  idx = (np.abs(array-value)).argmin()
  return idx

def _make_len_as_shortest(lhs_x, lhs_y, rhs_x, rhs_y):
  """Make both arrays of same shape as the shortest between them."""
  lhs_x, lhs_y = np.asarray(lhs_x), np.asarray(lhs_y)
  rhs_x, rhs_y = np.asarray(rhs_x), np.asarray(rhs_y)

  assert lhs_x.shape[0] == lhs_y.shape[0]
  assert rhs_x.shape[0] == rhs_y.shape[0]

  sorted_ = sorted([(lhs_x, lhs_y, lhs_x.shape[0]), (rhs_x, rhs_y, rhs_x.shape[0])],
                   key=lambda x: x[2])

  res_y = []
  res_x = []
  for i in range(sorted_[0][2]):
    idx = _find_nearest_idx(rhs_x, sorted_[0][0][i])
    res_y.append(sorted_[1][1][idx])
    res_x.append(idx)
  return np.asarray(res_x), np.asarray(res_y)
