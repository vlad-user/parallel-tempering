import os
import sys
import pickle
import json
import random

import numpy as np
import matplotlib.pyplot as plt
import pylatex as tex
from cycler import cycler

from simulator.plot import Plot
import simulator.simulator_utils as s_utils

class ReportGenerator:

  _colors = ['blue',
             'green',
             'red',
             'cyan',
             'magenta',
             'yellow',
             'black',
             'green',
             'purple',
             'plum',
             'orange']

  def __init__(self, files, labels, file_prefix='rep_gen_'):
    """Creates a new `ReportGenerator` instance.

    Args:
      `files`: A list of lists s.t. each list contains a filenames
        that should be grouped together and showed by the same curve.
      `labels`: A list of strings of labels for legend.
      `file_prefix`: A prefix that will be attached to all files
        generated by this instance (plot pngs and pdfs).
    """

    if not isinstance(files, list) or not files:
      raise ValueError('`files` must be non-empty list.')

    if not isinstance(labels, list) or not labels:
      raise ValueError('`labels` must be non-empty list.')

    if any(not isinstance(f, list) for f in files):
      raise ValueError('Each element in `files` must be a list.')

    if any(not f for f in files):
      raise ValueError('There are empty list in `files`.')

    if len(labels) != len(files):
      err_msg = ("`labels` list must be of same size as "
                 "`files` list.")
      raise ValueError(err_msg)

    dirname = os.path.join(os.path.dirname(os.path.abspath(__file__)),
                          'summaries',
                          'reports')

    if not os.path.exists(dirname):
      os.makedirs(dirname)

    self._dirname = os.path.join(dirname, file_prefix)

    if not os.path.exists(self._dirname):
      os.makedirs(self._dirname)

    for f in os.listdir(self._dirname):
      if f.endswith('.pdf') or f.endswith('.tex'):
        os.remove(os.path.join(self._dirname, f))

    self._images_dirname = os.path.join(self._dirname, 'images')

    if not os.path.exists(self._images_dirname):
      os.makedirs(self._images_dirname)

    self._mses = [MultiSummaryExtractor(f) for f in files]
    self._labels = labels
    self._file_prefix = file_prefix

    max_len = len(files)

    self._linewidths = [2 for i in range(max_len)]
    self._markers = ['o' for i in range(max_len)]

    self._width = r'1\textwidth'
    self._position = 'ht'
    self._pdf_filename = os.path.join(self._dirname, self._file_prefix)
    self._fig_width = 8
    self._fig_height = 4


  def generate_report(self, custom_text=None):
    """Generates pdf file with report for multiple experiments.

    Args:
      `custom_text`: A text that will be added to the beginning of the
        pdf file.
    """
    doc = tex.Document(self._pdf_filename)
    doc.append("""Results
        

        """)

    self._create_specs_table(doc)

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_sep_ratio_vs_err_differ())
      plot_.add_caption('Average overfitting for min value of test error vs separation ratio.')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_sep_ratio_vs_final_err_differ())
      plot_.add_caption('Average overfitting for final value of test error vs separation ratio.')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_diffusion_vs_min_error())
      plot_.add_caption('Average min 0-1 error vs average diffusion to achieve this error.')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_n_steps_vs_min_error())
      plot_.add_caption('Average min 0-1 error vs average epochs to achieve this error.')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_sep_ratio_vs_min_error())
      plot_.add_caption('Average min 0-1 error vs separation ratio.')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_sep_ratio_vs_accept_ratio())
      plot_.add_caption('Average accept ratio vs separation ratio.')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_sep_ratio_vs_mix_ratio())
      plot_.add_caption('Average mixing ratio vs separation ratio.')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_sep_ratio_vs_visit_ratio())
      plot_.add_caption('Average visiting ratio vs separation ratio.')
    plt.close()

    doc.generate_pdf(clean_tex=True)

  def _create_specs_table(self, doc):
    """Generates summary table."""
    
    col_names = ['Model',
                 'Dataset',
                 'Data Size',
                 "beta_0",
                 'Swap Step',
                 'Burn In',
                 'Batch Size',
                 'Noise Type',
                 'Proba Coeff']
    
    table_spec = "|@{}l@{}".join(['' for i in range(len(col_names) + 1)]) + '|'

    tabular = tex.Tabular(table_spec,
                          pos=self._position,
                          booktabs=False,
                          row_height=0.1,)


    with doc.create(tabular) as table:
      table.add_hline()
      table.add_row(col_names)
      table.add_hline()
      for i, mse in enumerate(self._mses):
        for summ_ext in mse._summ_ext:
          vals_ = {n:[] for n in col_names}
          se = mse._summ_ext[summ_ext]
          desc = se.get_description()
          vals_['Model'].append(s_utils.get_value_from_name(
              se.get_name(), 'model_name'))
          vals_['Dataset'].append(s_utils.get_value_from_name(
              se.get_name(), 'dataset_name'))
          vals_['Data Size'].append(s_utils.get_value_from_name(
              se.get_name(), 'train_data_size'))
          vals_["beta_0"].append(s_utils.get_value_from_name(
              se.get_name(), 'beta_0'))
          vals_['Swap Step'].append(desc['swap_step'])
          vals_['Burn In'].append(desc['burn_in_period'])
          vals_['Batch Size'].append(desc['batch_size'])
          vals_['Noise Type'].append(desc['noise_type'])
          vals_['Proba Coeff'].append(desc['proba_coeff'])

        for k in vals_:
          vals_[k] = list(set(vals_[k]))
        row = []
        for col_name in col_names:
          if len(vals_[col_name]) == 1:
            row.append(tex.basic.TextColor(self._colors[i],
                                           str(vals_[col_name][0])))
          else:
            row.append(' ')

        table.add_row(row)
        table.add_hline()


  def _plot_diffusion_vs_min_error(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()
    for i, mse in enumerate(self._mses):
      diff_vals, err_vals, seps = (
          mse.get_diffusion_vs_min_error())
      annotation = [(str(seps[j]), diff_vals[j], err_vals[j])
                    for j in range(len(diff_vals))]

      figs.append(plot.plot(x=diff_vals,
                            y=err_vals,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i],
                            annotate=annotation))
    plot.legend(fig,
                ax,
                xlabel='AVERAGE DIFFUSION',
                ylabel='AVERAGE MIN 0-1 ERROR',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))

    img_path = os.path.join(self._images_dirname, 'diffusion.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_n_steps_vs_min_error(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()
    for i, mse in enumerate(self._mses):
      step_vals, err_vals, seps = (
          mse.get_n_steps_vs_min_error())
      annotation = [(str(seps[j]), step_vals[j], err_vals[j])
                    for j in range(len(step_vals))]
      figs.append(plot.plot(x=step_vals,
                            y=err_vals,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i],
                            annotate=annotation))
    plot.legend(fig,
                ax,
                xlabel='AVERAGE EPOCHS',
                ylabel='AVERAGE MIN 0-1 ERROR',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))

    img_path = os.path.join(self._images_dirname, 'n_steps.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_sep_ratio_vs_min_error(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()

    for i, mse in enumerate(self._mses):
      seps, errs, stddevs = mse.get_sep_ratio_vs_min_error()

      figs.append(plot.plot(x=seps,
                            y=errs,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i]))
    plot.legend(fig,
                ax,
                xlabel='SEPARATION RATIO',
                ylabel='AVERAGE MIN 0-1 ERROR',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))
    img_path = os.path.join(self._images_dirname, 'min_loss_sep.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_sep_ratio_vs_accept_ratio(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()

    for i, mse in enumerate(self._mses):
      seps, accs, errs = mse.get_sep_ratio_vs_accept_ratio()

      figs.append(plot.plot(x=seps,
                            y=accs,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i]))
    plot.legend(fig,
                ax,
                xlabel='SEPARATION RATIO',
                ylabel='ACCEPT RATIO',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))
    img_path = os.path.join(self._images_dirname, 'sep_vs_accept.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_sep_ratio_vs_mix_ratio(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()

    for i, mse in enumerate(self._mses):
      seps, mixs, errs = mse.get_sep_ratio_vs_mix_ratio()

      figs.append(plot.plot(x=seps,
                            y=mixs,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i]))
    plot.legend(fig,
                ax,
                xlabel='SEPARATION RATIO',
                ylabel='MIXING RATIO',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))
    img_path = os.path.join(self._images_dirname, 'sep_vs_mix.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_sep_ratio_vs_visit_ratio(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()

    for i, mse in enumerate(self._mses):
      seps, visits, errs = mse.get_sep_ratio_vs_visit_ratio()

      figs.append(plot.plot(x=seps,
                            y=visits,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i]))
    plot.legend(fig,
                ax,
                xlabel='SEPARATION RATIO',
                ylabel='VISIT RATIO',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))
    img_path = os.path.join(self._images_dirname, 'sep_vs_visit.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_sep_ratio_vs_err_differ(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()

    for i, mse in enumerate(self._mses):
      seps, visits, errs = mse.get_sep_ratio_vs_err_differ()

      figs.append(plot.plot(x=seps,
                            y=visits,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i]))
    plot.legend(fig,
                ax,
                xlabel='SEPARATION RATIO',
                ylabel='OVERFITTING ERROR',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))
    img_path = os.path.join(self._images_dirname, 'sep_vs_min_overfit.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_sep_ratio_vs_final_err_differ(self):
    fig, ax = plt.subplots()
    figs = []
    plot = Plot()

    for i, mse in enumerate(self._mses):
      seps, visits, errs = mse.get_sep_ratio_vs_final_err_differ()

      figs.append(plot.plot(x=seps,
                            y=visits,
                            fig=fig,
                            ax=ax,
                            label=self._labels[i],
                            color=self._colors[i],
                            splined_points_mult=None,
                            linewidth=self._linewidths[i],
                            marker=self._markers[i]))
    plot.legend(fig,
                ax,
                xlabel='SEPARATION RATIO',
                ylabel='FINAL OVERFITTING ERROR',
                fig_width=self._fig_width,
                fig_height=self._fig_height,
                bbox_to_anchor=(1.15, 0.5))
    img_path = os.path.join(self._images_dirname, 'sep_vs_final_overfit.png')
    fig.savefig(img_path, bbox_inches='tight')
    return img_path




class MultiSummaryExtractor:

  def __init__(self, names):
    """Instantiates a new MultiSummaryExtractor instance.

    Args:
      `names`: A list of simulation names.

    Raises:
      ValueError: If for any simulation name in `names` the simulation
        do not exist.
      TypeError: If `names` is not `list` or `names` is an empty list.
    """
    dirname = os.path.abspath(os.path.dirname(__file__))
    self._dirname = os.path.join(dirname, 'summaries')
    filenames = os.listdir(self._dirname)
    
    if not isinstance(names, list) or not names:
      raise TypeError("`names` argument must be non-empty list.")
    if any(name not in filenames for name in names):
      raise ValueError('The following simulation(s) do not exist(s):',
                       [name for name in names if name not in filenames])
    self._summ_ext = {
        name:SummaryExtractor(name)
        for name in names
    }

  def get_sep_ratio_vs_accept_ratio(self):
    """Returns data (sep_ratio list, `accept_ratio` list, stddev list)."""

    sep_ratios = []
    accept_ratios = []
    errs = []

    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, acc, stddev = se.get_sep_ratio_vs_accept_ratio()
      sep_ratios.append(sep)
      accept_ratios.append(acc)
      errs.append(stddev)

    x, y, z = zip(*sorted(zip(sep_ratios, accept_ratios, errs)))

    return list(x), list(y), list(z)

  def get_sep_ratio_vs_mix_ratio(self):
    """Returns data (sep_ratio list, `accept_ratio` list, stddev list)."""

    sep_ratios = []
    mix_ratios = []
    errs = []

    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, mix, stddev = se.get_sep_ratio_vs_mix_ratio()
      sep_ratios.append(sep)
      mix_ratios.append(mix)
      errs.append(stddev)

    x, y, z = zip(*sorted(zip(sep_ratios, mix_ratios, errs)))

    return list(x), list(y), list(z)

  def get_sep_ratio_vs_visit_ratio(self):
    """Returns data (sep_ratio list, `accept_ratio` list, stddev list)."""

    sep_ratios = []
    visit_ratios = []
    errs = []

    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, visit, stddev = se.get_sep_ratio_vs_visit_ratio()
      sep_ratios.append(sep)
      visit_ratios.append(visit)
      errs.append(stddev)

    x, y, z = zip(*sorted(zip(sep_ratios, visit_ratios, errs)))

    return list(x), list(y), list(z)

  def get_diffusion_vs_min_error(self):
    sep_ratios = []
    diff_vals = []
    errs = []

    for name in self._summ_ext:
      se = self._summ_ext[name]
      diff_val, diff_err, loss_val, loss_err, sep = (
          se.get_diffusion_vs_min_error())
      sep_ratios.append(sep)
      diff_vals.append(diff_val)
      errs.append(loss_val)

    x, y, z = zip(*sorted(zip(diff_vals, errs, sep_ratios)))

    return list(x), list(y), list(z)

  def get_n_steps_vs_min_error(self):
    sep_ratios = []
    err_vals = []
    step_vals = []


    for name in self._summ_ext:
      se = self._summ_ext[name]
      step_val, step_err, loss_val, loss_err, sep = (
          se.get_n_steps_vs_min_error())
      sep_ratios.append(sep)
      step_vals.append(step_val)
      err_vals.append(loss_val)

    x, y, z = zip(*sorted(zip(step_vals, err_vals, sep_ratios)))

    return list(x), list(y), list(z)

  def get_sep_ratio_vs_min_error(self):
    sep_ratios = []
    err_vals = []
    err_errs = []

    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, loss_val, loss_err = se.get_sep_ratio_vs_min_error()
      sep_ratios.append(sep)
      err_vals.append(loss_val)
      err_errs.append(loss_err)

    x, y, z = zip(*sorted(zip(sep_ratios, err_vals, err_errs)))

    return list(x), list(y), list(z)

  def get_sep_ratio_vs_err_differ(self):
    sep_ratios = []
    err_vals = []
    err_errs = []

    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, differ, differ_std = se.get_sep_ratio_vs_err_differ()
      sep_ratios.append(sep)
      err_vals.append(differ)
      err_errs.append(differ_std)

    x, y, z = zip(*sorted(zip(sep_ratios, err_vals, err_errs)))

    return list(x), list(y), list(z)

  def get_sep_ratio_vs_final_err_differ(self):
    sep_ratios = []
    err_vals = []
    err_errs = []

    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, differ, differ_std = se.get_sep_ratio_vs_final_err_differ()
      sep_ratios.append(sep)
      err_vals.append(differ)
      err_errs.append(differ_std)

    x, y, z = zip(*sorted(zip(sep_ratios, err_vals, err_errs)))

    return list(x), list(y), list(z)

class SummaryReportGenerator:
  """Generates pdf report for individual simulations."""

  _colors = plt.rcParams['axes.prop_cycle'].by_key()['color']
  _colors += ['blue',
              'orange',
              'purple',
              'dimgray',
              'maroon',
              'gold',
              'rosybrown',
              'tomato']
  _colors += _colors
  def __init__(self, names, labels, simulation_num=0, report_name='summary_report', sample_every=1,
               lower=500, higher=700):
    self._simulation_num = simulation_num
    self._summ_ext = {f:SummaryExtractor(f) for f in names}
    self._original_names = []
    for i, name in enumerate(names):
      self._original_names.append(self._summ_ext[name]._name)
      self._summ_ext[name]._original_name = self._summ_ext[name]._name
      self._summ_ext[name]._name = labels[i]
    dirname = os.path.abspath(os.path.dirname(__file__))
    dirname = os.path.join(dirname, 'summaries', 'reports')
    if not os.path.exists(dirname):
      os.makedirs(self._dirname)

    self._dirname = os.path.join(dirname, report_name)
    self._images_dirname = os.path.join(self._dirname, 'images')
    self._pdf_filename = os.path.join(self._dirname, report_name)
    self._sample_every = sample_every
    if not os.path.exists(self._images_dirname):
      os.makedirs(self._images_dirname)

    self._width = r'1\textwidth'
    self._position = 'ht'
    self.yaxis_cycle = cycler(y=[0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72])
    self.lower = lower
    self.higher = higher

  def generate_report(self, custom_text="Results"):
    """Generates pdf file with report for for multiple individual simulations.

    Args:
      `custom_text`: A text that will be added to the beginning of the
        pdf file.
    """
    doc = tex.Document(self._pdf_filename,
                       font_size='tiny')
    doc.append(custom_text)
    doc.append(tex.LineBreak())

    self._create_specs_table(doc)

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_train_test_min_error(self._sample_every,
                                                      self._simulation_num))
      plot_.add_caption('Train-test min error')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_train_test_min_error_with_markers(self._sample_every,
                                                                   self._simulation_num,
                                                                   lower=self.lower,
                                                                   higher=self.higher))
      plot_.add_caption('Train-test min error with swap markers')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_train_test_min_loss(self._sample_every,
                                                     self._simulation_num))
      plot_.add_caption('Train-test min loss')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_train_test_min_loss_with_markers(self._sample_every,
                                                                  self._simulation_num,
                                                                  lower=self.lower,
                                                                  higher=self.higher))
      plot_.add_caption('Train-test min loss with swap markers')
    plt.close()

    for name, se in self._summ_ext.items():
      with doc.create(tex.Figure(position=self._position)) as plot_:
        plot_.add_image(self._plot_train_test_error_per_sim(se,
                                                            self._sample_every,
                                                            self._simulation_num))
        plot_.add_caption('Train-test error for ' + se.get_name())
      plt.close()

    for name, se in self._summ_ext.items():
      with doc.create(tex.Figure(position=self._position)) as plot_:
        plot_.add_image(self._plot_train_test_loss_per_sim(se,
                                                           self._sample_every,
                                                           self._simulation_num))
        plot_.add_caption('Train-test loss for ' + se.get_name())
      plt.close()

    for name, se in self._summ_ext.items():
      with doc.create(tex.Figure(position=self._position)) as plot_:
        plot_.add_image(self._plot_mixing(se, self._simulation_num))
        plot_.add_caption('Mixing ' + se.get_name())
      plt.close()

    for name, se in self._summ_ext.items():
      with doc.create(tex.Figure(position=self._position)) as plot_:
        plot_.add_image(self._plot_diffusion(se, self._simulation_num))
        plot_.add_caption('Diffusion ' + se.get_name())
      plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_train_test_error(self._sample_every,
                                                  self._simulation_num))
      plot_.add_caption('Train-test error (everything together)')
    plt.close()

    with doc.create(tex.Figure(position=self._position)) as plot_:
      plot_.add_image(self._plot_train_test_loss(self._sample_every,
                                                 self._simulation_num))
      plot_.add_caption('Train-test loss (everything together)')
    plt.close()

    doc.generate_pdf(clean_tex=True)



  def generate_min_loss_err_report(self, simulation_nums, custom_text='Results'):
    doc = doc = tex.Document(self._pdf_filename,
                       font_size='tiny')
    doc.append(custom_text)
    doc.append(tex.LineBreak())

    self._create_specs_table(doc)
    for s in simulation_nums:
      with doc.create(tex.Figure(position=self._position)) as plot_:
        plot_.add_image(self._plot_train_test_min_error(self._sample_every,
                                                        simulation_num=s))
        plot_.add_caption('Train-test min error ' + str(s))
      plt.close()

      with doc.create(tex.Figure(position=self._position)) as plot_:
        plot_.add_image(self._plot_train_test_min_loss(self._sample_every,
                                                       simulation_num=s))
        plot_.add_caption('Train-test min loss ' + str(s))
      plt.close()
    doc.generate_pdf(clean_tex=True)

  def _plot_train_test_error(self, sample_every=1, simulation_num=0):
    fig, ax = plt.subplots()
    plot = Plot()

    color_idx = 0
    for name in self._summ_ext:
      se = self._summ_ext[name]

      for r in range(se.get_description()['n_replicas']):
        
        x, y = se.get_summary(summ_name='test_error',
                              replica_id=r,
                              simulation_num=self._simulation_num)
        x1, y1 = se.get_summary(summ_name='train_error',
                                replica_id=r,
                                simulation_num=self._simulation_num)
        n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1

        if se.get_description()['n_replicas'] == 1:
          label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
          label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
          color = 'black'
          linestyle_test = '-'
          linestyle_train = '--'
          linewidth_train = 2
          linewidth_test = 2
        else:
          label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
          label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
          color = self._colors[color_idx]
          linestyle_test = '-'
          linestyle_train = '--'
          linewidth_train = 1.5
          linewidth_test = 1.5
          color_idx += 1
        
        plot.plot(x,
                  y,
                  fig=fig,
                  ax=ax,
                  label=label_test,
                  linewidth=linewidth_test,
                  color=color,
                  linestyle=linestyle_test,
                  splined_points_mult=None)

        #y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
        y1 = y1[::sample_every]
        

        plot.plot(np.linspace(start=0, stop=n_epochs, num=len(y1)),
                  y1,
                  fig=fig,
                  ax=ax,
                  label=label_train,
                  linewidth=linewidth_train,
                  linestyle=linestyle_train,
                  color=color,
                  splined_points_mult=None)

    plot.legend(fig=fig,
                ax=ax,
                xlabel='EPOCHS',
                ylabel='ERROR',)
    img_path = os.path.join(self._images_dirname, 'train_test_error.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_min_error_with_markers(self, sample_every=1, simulation_num=0, lower=500, higher=700):
    
    def _get_next_yloc():
      for y in self.yaxis_cycle*10000:
        yield y['y']
    fig, ax = plt.subplots()
    plot = Plot()
    color_idx = 0
    added_noise_keys = None
    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, loss_val, loss_err = se.get_sep_ratio_vs_min_error()
      min_rid = se._vals['replica_id_min_err_sim_' + str(simulation_num)]
      x, y = se.get_summary(summ_name='test_error',
                            replica_id=min_rid,
                            simulation_num=simulation_num)
      x1, y1 = se.get_summary(summ_name='train_error',
                              replica_id=min_rid,
                              simulation_num=simulation_num)
      n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1
      prev_x = x.copy()
      prev_x1 = x1.copy()
      x = [x[i] for i in range(len(y)) if lower <= prev_x[i] <= higher]
      y = [y[i] for i in range(len(y)) if lower <= prev_x[i] <= higher]

      x1 = [x1[i] for i in range(len(y1)) if lower <= prev_x1[i] <= higher]
      y1 = [y1[i] for i in range(len(y1)) if lower <= prev_x1[i] <= higher]
      n_epochs = higher - lower
      if se.get_description()['n_replicas'] == 1:
        label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        color = 'black'
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 2
        linewidth_test = 2
      else:
        label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        color = self._colors[color_idx]
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 1.5
        linewidth_test = 1.5
        color_idx += 1

      plot.plot(x,
                y,
                fig=fig,
                ax=ax,
                label=label_test,
                linewidth=linewidth_test,
                color=color,
                linestyle=linestyle_test,
                splined_points_mult=None)

      plot.plot(x1,
                y1,
                fig=fig,
                ax=ax,
                label=label_train,
                linewidth=linewidth_train,
                linestyle=linestyle_train,
                color=color,
                splined_points_mult=None)
      x, noise_vals = se.get_summary('noise_values', replica_id=min_rid, simulation_num=simulation_num)
      noises = sorted(list(set(noise_vals)))
      noises = [(n, i) for i, n in enumerate(noises)]
      noise_keys = {n:i for n, i in noises}
      next_yloc = _get_next_yloc()
      for i, noise in enumerate(noise_vals):

        if i > 0 and lower <= x[i] <= higher and noise != noise_vals[i-1]:
          ax.axvline(x[i])
          ax.text(x[i-1], next_yloc.__next__(), str(noise_keys[noise_vals[i-1]]) + '->' + str(noise_keys[noise]))
          added_noise_keys = noise_keys
          
    if added_noise_keys:
      xlabel = 'EPOCHS\n' + json.dumps(added_noise_keys)
    else:
      xlabel = 'EPOCHS'
    plot.legend(fig=fig,
                ax=ax,
                xlabel=xlabel,
                ylabel='ERROR',)
    img_path = os.path.join(self._images_dirname,
                            'train_test_min_error_with_markers' + str(simulation_num) + '.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_min_error(self, sample_every=1, simulation_num=0, avg_interval=250):
    fig, ax = plt.subplots()
    plot = Plot()
    color_idx = 0
    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, loss_val, loss_err = se.get_sep_ratio_vs_min_error()
      min_rid = se._vals['replica_id_min_err_sim_' + str(simulation_num)]
      x, y = se.get_summary(summ_name='test_error',
                            replica_id=min_rid,
                            simulation_num=simulation_num)
      x1, y1 = se.get_summary(summ_name='train_error',
                              replica_id=min_rid,
                              simulation_num=simulation_num)
      n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1

      if se.get_description()['n_replicas'] == 1:
        label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        color = 'black'
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 2
        linewidth_test = 2
      else:
        label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        color = self._colors[color_idx]
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 1.5
        linewidth_test = 1.5
        color_idx += 1
      #y_vals = y[5:].copy()
      #chunkified = [(np.mean(s), int((idx + 1)*avg_interval/2)) 
      #              for idx, s in enumerate(y_vals[i:i+avg_interval] for i in range(0, len(y_vals), avg_interval))]
      #annots = [("{0:.3f}".format(c[0]), x[_find_nearest_idx(x, c[1])], )]
      plot.plot(x,
                y,
                fig=fig,
                ax=ax,
                label=label_test,
                linewidth=linewidth_test,
                color=color,
                linestyle=linestyle_test,
                splined_points_mult=None)

      y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
      y1 = y1[::sample_every]
      

      plot.plot(np.linspace(start=0, stop=n_epochs, num=len(y1)),
                y1,
                fig=fig,
                ax=ax,
                label=label_train,
                linewidth=linewidth_train,
                linestyle=linestyle_train,
                color=color,
                splined_points_mult=None)

    plot.legend(fig=fig,
                ax=ax,
                xlabel='EPOCHS',
                ylabel='ERROR',)
    img_path = os.path.join(self._images_dirname,
                            'train_test_min_error' + str(simulation_num) + '.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_min_loss(self, sample_every=1, simulation_num=0):
    fig, ax = plt.subplots()
    plot = Plot()
    color_idx = 0
    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, loss_val, loss_err = se.get_sep_ratio_vs_min_error()
      min_rid = se._vals['replica_id_min_err_sim_' + str(simulation_num)]

      x, y = se.get_summary(summ_name='test_loss',
                            replica_id=min_rid,
                            simulation_num=simulation_num)
      x1, y1 = se.get_summary(summ_name='train_loss',
                              replica_id=min_rid,
                              simulation_num=simulation_num)
      n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1

      if se.get_description()['n_replicas'] == 1:
        label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        color = 'black'
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 2
        linewidth_test = 2
      else:
        label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        color = self._colors[color_idx]
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 1.5
        linewidth_test = 1.5
        color_idx += 1
      
      plot.plot(x,
                y,
                fig=fig,
                ax=ax,
                label=label_test,
                linewidth=linewidth_test,
                color=color,
                linestyle=linestyle_test,
                splined_points_mult=None)

      y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
      y1 = y1[::sample_every]
      

      plot.plot(np.linspace(start=0, stop=n_epochs, num=len(y1)),
                y1,
                fig=fig,
                ax=ax,
                label=label_train,
                linewidth=linewidth_train,
                linestyle=linestyle_train,
                color=color,
                splined_points_mult=None)

    plot.legend(fig=fig,
                ax=ax,
                xlabel='EPOCHS',
                ylabel='LOSS',)
    img_path = os.path.join(self._images_dirname,
                            'train_test_min_loss' + str(simulation_num) + '.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_min_loss_with_markers(self, sample_every=1, simulation_num=0, lower=500, higher=700):
    #yaxis_cycle = cycler(y=[0.66, 0.68, 0.7, 0.72, 0.7, 0.68])
    def _get_next_yloc():
      for y in self.yaxis_cycle*10000:
        yield y['y']
    fig, ax = plt.subplots()
    plot = Plot()
    color_idx = 0
    added_noise_keys = None
    for name in self._summ_ext:
      se = self._summ_ext[name]
      sep, loss_val, loss_err = se.get_sep_ratio_vs_min_error()
      min_rid = se._vals['replica_id_min_err_sim_' + str(simulation_num)]
      x, y = se.get_summary(summ_name='test_loss',
                            replica_id=min_rid,
                            simulation_num=simulation_num)
      x1, y1 = se.get_summary(summ_name='train_loss',
                              replica_id=min_rid,
                              simulation_num=simulation_num)
      n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1
      prev_x = x.copy()
      prev_x1 = x1.copy()
      x = [x[i] for i in range(len(y)) if lower <= prev_x[i] <= higher]
      y = [y[i] for i in range(len(y)) if lower <= prev_x[i] <= higher]

      x1 = [x1[i] for i in range(len(y1)) if lower <= prev_x1[i] <= higher]
      y1 = [y1[i] for i in range(len(y1)) if lower <= prev_x1[i] <= higher]
      n_epochs = higher - lower
      if se.get_description()['n_replicas'] == 1:
        label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        color = 'black'
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 2
        linewidth_test = 2
      else:
        label_test = se.get_name() + '_test_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y))
        label_train = se.get_name() + '_train_' + str(min_rid) + '_min:' + "{0:.3f}".format(min(y1))
        color = self._colors[color_idx]
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 1.5
        linewidth_test = 1.5
        color_idx += 1

      plot.plot(x,
                y,
                fig=fig,
                ax=ax,
                label=label_test,
                linewidth=linewidth_test,
                color=color,
                linestyle=linestyle_test,
                splined_points_mult=None)

      plot.plot(x1,
                y1,
                fig=fig,
                ax=ax,
                label=label_train,
                linewidth=linewidth_train,
                linestyle=linestyle_train,
                color=color,
                splined_points_mult=None)
      x, noise_vals = se.get_summary('noise_values', replica_id=min_rid, simulation_num=simulation_num)
      noises = sorted(list(set(noise_vals)))
      noises = [(n, i) for i, n in enumerate(noises)]
      noise_keys = {n:i for n, i in noises}
      next_yloc = _get_next_yloc()
      text_loc = max(y)//2
      for i, noise in enumerate(noise_vals):

        if i > 0 and lower <= x[i] <= higher and noise != noise_vals[i-1]:
          ax.axvline(x[i])
          ax.text(x[i-1], text_loc + next_yloc.__next__()*5, str(noise_keys[noise_vals[i-1]]) + '->' + str(noise_keys[noise]))
          added_noise_keys = noise_keys
          
    if added_noise_keys:
      xlabel = 'EPOCHS\n' + json.dumps(added_noise_keys)
    else:
      xlabel = 'EPOCHS'
    plot.legend(fig=fig,
                ax=ax,
                xlabel=xlabel,
                ylabel='ERROR',)
    img_path = os.path.join(self._images_dirname,
                            'train_test_min_loss_with_markers' + str(simulation_num) + '.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_loss(self, summ_name, sample_every=1, simulation_num=0):
    fig, ax = plt.subplots()
    plot = Plot()

    color_idx = 0
    for name in self._summ_ext:
      se = self._summ_ext[name]
      for r in range(se.get_description()['n_replicas']):
        x, y = se.get_summary(summ_name=summ_name,
                              replica_id=r,
                              simulation_num=simulation_num)
        if se.get_description()['n_replicas'] == 1:
          color = 'black'
        else:
          color = self._colors[color_idx]

  def _plot_train_test_loss(self, sample_every=1, simulation_num=0):
    fig, ax = plt.subplots()
    plot = Plot()

    color_idx = 0
    for name in self._summ_ext:
      se = self._summ_ext[name]

      for r in range(se.get_description()['n_replicas']):
        
        x, y = se.get_summary(summ_name='test_loss',
                              replica_id=r,
                              simulation_num=simulation_num)
        x1, y1 = se.get_summary(summ_name='train_loss',
                                replica_id=r,
                                simulation_num=simulation_num)
        n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1

        if se.get_description()['n_replicas'] == 1:
          label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
          label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
          color = 'black'
          linestyle_test = '-'
          linestyle_train = '--'
          linewidth_train = 2
          linewidth_test = 2
        else:
          label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
          label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
          color = self._colors[color_idx]
          linestyle_test = '-'
          linestyle_train = '--'
          linewidth_train = 1.5
          linewidth_test = 1.5
          color_idx += 1
        
        plot.plot(x,
                  y,
                  fig=fig,
                  ax=ax,
                  label=label_test,
                  linewidth=linewidth_test,
                  color=color,
                  linestyle=linestyle_test,
                  splined_points_mult=None)

        y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
        y1 = y1[::sample_every]
        

        plot.plot(np.linspace(start=0, stop=n_epochs, num=len(y1)),
                  y1,
                  fig=fig,
                  ax=ax,
                  label=label_train,
                  linewidth=linewidth_train,
                  linestyle=linestyle_train,
                  color=color,
                  splined_points_mult=None)

    plot.legend(fig=fig,
                ax=ax,
                xlabel='EPOCHS',
                ylabel='ERROR',)
    img_path = os.path.join(self._images_dirname, 'train_test_loss.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_error_per_sim(self, se, sample_every=1, simulation_num=0):
    fig, ax = plt.subplots()
    plot = Plot()


    color_idx = 0
    for r in range(se.get_description()['n_replicas']):
        
      x, y = se.get_summary(summ_name='test_error',
                            replica_id=r,
                            simulation_num=simulation_num)
      x1, y1 = se.get_summary(summ_name='train_error',
                              replica_id=r,
                              simulation_num=simulation_num)
      n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1

      if se.get_description()['n_replicas'] == 1:
        label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
        label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
        color = 'black'
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 2
        linewidth_test = 2
      else:
        label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
        label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
        color = self._colors[color_idx]
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 1.5
        linewidth_test = 1.5
        color_idx += 1
      
      plot.plot(x,
                y,
                fig=fig,
                ax=ax,
                label=label_test,
                linewidth=linewidth_test,
                color=color,
                linestyle=linestyle_test,
                splined_points_mult=None)

      y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
      y1 = y1[::sample_every]
      

      plot.plot(np.linspace(start=0, stop=n_epochs, num=len(y1)),
                y1,
                fig=fig,
                ax=ax,
                label=label_train,
                linewidth=linewidth_train,
                linestyle=linestyle_train,
                color=color,
                splined_points_mult=None)

    plot.legend(fig=fig,
                ax=ax,
                xlabel='EPOCHS',
                ylabel='ERROR',)
    img_path = os.path.join(
        self._images_dirname, 
        'train_test_error_per_sim'+se.get_name()+'.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_train_test_loss_per_sim(self, se, sample_every=1, simulation_num=0):
    fig, ax = plt.subplots()
    plot = Plot()


    color_idx = 0
    for r in range(se.get_description()['n_replicas']):
        
      x, y = se.get_summary(summ_name='test_loss',
                            replica_id=r,
                            simulation_num=simulation_num)
      x1, y1 = se.get_summary(summ_name='train_loss',
                              replica_id=r,
                              simulation_num=simulation_num)
      n_epochs = se._summaries[simulation_num]['latest_epoch'] + 1

      if se.get_description()['n_replicas'] == 1:
        label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
        label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
        color = 'black'
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 2
        linewidth_test = 2
      else:
        label_test = se.get_name() + '_test_' + str(r) + '_min:' + "{0:.3f}".format(min(y))
        label_train = se.get_name() + '_train_' + str(r) + '_min:' + "{0:.3f}".format(min(y1))
        color = self._colors[color_idx]
        linestyle_test = '-'
        linestyle_train = '--'
        linewidth_train = 1.5
        linewidth_test = 1.5
        color_idx += 1
      
      plot.plot(x,
                y,
                fig=fig,
                ax=ax,
                label=label_test,
                linewidth=linewidth_test,
                color=color,
                linestyle=linestyle_test,
                splined_points_mult=None)

      y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
      y1 = y1[::sample_every]
      

      plot.plot(np.linspace(start=0, stop=n_epochs, num=len(y1)),
                y1,
                fig=fig,
                ax=ax,
                label=label_train,
                linewidth=linewidth_train,
                linestyle=linestyle_train,
                color=color,
                splined_points_mult=None)

    plot.legend(fig=fig,
                ax=ax,
                xlabel='EPOCHS',
                ylabel='ERROR',)
    img_path = os.path.join(
        self._images_dirname, 
        'train_test_loss_per_sim'+se.get_name()+'.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_mixing(self, se, simulation_num=0):
    fig = se._plot_mixing(simulation_num)

    img_path = os.path.join(self._images_dirname, se.get_name() + 'mixing.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _plot_diffusion(self, se, simulation_num=0):
    fig = se._plot_diffusion(simulation_num)

    img_path = os.path.join(self._images_dirname, se.get_name() + 'diffusion.png')
    plt.savefig(img_path, bbox_inches='tight')
    return img_path

  def _create_specs_table(self, doc):
    """Generates summary table."""
    #original_names = "\n".join(self._original_names)
    for name in self._original_names:

      doc.append(name)
      doc.append(tex.LineBreak())
      doc.append(str(self._summ_ext[name].get_description()['noise_list']))
      doc.append(tex.LineBreak())
    doc.append(tex.LineBreak())

    col_names = ['Name',
                 'Accept',
                 'Mixing',
                 'Visit',
                 'TestErr',
                 'BurnIn',
                 'Swap',
                 'Sep',
                 'Coeff',
                 'DSize',
                 'LR',
                 'Batch',
                 '#params']

    table_spec = "|@{}l@{}".join(['' for i in range(len(col_names) + 1)]) + '|'

    tabular = tex.Tabular(table_spec,
                          pos=self._position,
                          booktabs=False,
                          row_height=0.1,)

    with doc.create(tabular) as table:
      table.add_hline()
      table.add_row(col_names)
      table.add_hline()
      
      for summ_ext in self._summ_ext:
        vals_ = {n:[] for n in col_names}
        se = self._summ_ext[summ_ext]
        desc = se.get_description()
        
        vals_['Accept'].append("{0:.3f}".format(se.get_accept_ratio()))
        vals_['Mixing'].append("{0:.3f}".format(se.get_mix_ratio()))
        vals_['Visit'].append("{0:.3f}".format(se.get_visit_ratio()))
        sep, err, std = se.get_sep_ratio_vs_min_error()
        vals_['TestErr'].append("{0:.3f}".format(err))
        vals_['BurnIn'].append(str(desc['burn_in_period']))
        vals_['Name'].append(se.get_name())
        vals_['Swap'].append(str(desc['swap_step']))
        vals_['Sep'].append(desc['separation_ratio'])
        vals_['Coeff'].append(desc['proba_coeff'])
        vals_['LR'].append(desc['learning_rate'])
        vals_['Batch'].append(desc['batch_size'])
        train_data_size = s_utils.get_value_from_name(se._original_name, 'train_data_size')
        vals_['DSize'].append(train_data_size)
        vals_['#params'].append(desc['n_params'])
        for k in vals_:
          vals_[k] = list(set(vals_[k]))
        row = []
        for col_name in col_names:
          if len(vals_[col_name]) == 1:
            row.append(str(vals_[col_name][0]))
          else:
            row.append(' ')

        table.add_row(row)
        table.add_hline()
    
class SummaryExtractor:

  def __init__(self, name):
    dirname = os.path.abspath(os.path.dirname(__file__))
    self._name = name
    self._dirname = os.path.join(dirname, 'summaries', name)
    filenames = sorted([f for f in os.listdir(self._dirname) if 'summary' in f],
                       key=lambda x: int(x.split('_')[1].split('.')[0]))
    description_path = os.path.join(self._dirname, 'description.json')
    self._summaries = []
    self._n_simulations = len(filenames)
    for f in filenames:
      filepath = os.path.join(self._dirname, f)
      try:
        with open(filepath, 'rb', os.O_NONBLOCK) as fo:
          self._summaries.append(pickle.load(fo))
      except EOFError:
        print(f)
        print(filepath)
        raise
    with open(description_path, 'r') as fo:
      self._description = json.load(fo)

    self._vals = {
        'accept_ratio': None,
        'mix_ratio': None,
        'visit_ratio': None,
        'accept_ratio_err': None,
        'visit_ratio_err': None,
        'avg_min_error': None,
        'avg_min_error_err': None,
        'avg_diff_for_min_error': None,
        'avg_diff_for_min_error_err': None,
        'avg_steps_for_min_error': None, # steps == epochs
        'avg_steps_for_min_error_err': None,
        'avg_err_differ': None,
        'avg_err_differ_err':None,
        'avg_err_final_differ':None,
        'avg_err_final_differ_err':None,
        '__debug__visit_raw':[],
        '__debug__err_differ': None,

    }

    self._n_replicas = self.get_description()['n_replicas']
    self._colors = plt.rcParams['axes.prop_cycle'].by_key()['color']

  def get_name(self):
    return self._name

  def get_sep_ratio_vs_final_err_differ(self):
    """Returns final difference between test-train error."""

    if self._vals['avg_err_final_differ'] is None:
      _ = self.get_sep_ratio_vs_err_differ()

    err_differ = self._vals['avg_err_final_differ']
    err_differ_std = self._vals['avg_err_final_differ_err']
    sep = self.get_description()['separation_ratio']

    return sep, err_differ, err_differ_std

  def get_sep_ratio_vs_err_differ(self):
    """Returns differences between test-train error.

    Differences are calculated:
      `min(test error) - train error[argmin(test_error)]`
    and returned averages over all simulations.
    """

    sep = self.get_description()['separation_ratio']
    if self._vals['avg_err_differ'] is not None:
      err_differ = self._vals['avg_err_differ']
      err_differ_std = self._vals['avg_err_differ_err']
      return sep, err_differ, err_differ_std
    err_differs = []
    err_final_differs = []
    reps = {i:[]
            for i in range(self._n_replicas)}

    reps_final = {i:[]
                  for i in range(self._n_replicas)}

    for s in range(self._n_simulations):
      for r in range(self._n_replicas):
        test_x, test_y = self.get_summary('test_error',
                                          replica_id=r,
                                          simulation_num=s)
        train_x, train_y = self.get_summary('train_error',
                                            replica_id=r,
                                            simulation_num=s)
        _, test_steps = self.get_summary('test_steps',
                                          replica_id=r,
                                          simulation_num=s)
        _, train_steps = self.get_summary('train_steps',
                                           replica_id=r,
                                           simulation_num=s)

        idx_test = np.argmin(test_y)
        idx_train = _find_nearest_idx(train_steps, test_steps[idx_test])
        differ = test_y[idx_test] - train_y[idx_train]
        reps[r].append(differ)
        err_differs.append(differ)

        idx_test = len(test_y) - 1
        differ = test_y[idx_test] - np.mean(train_y[-s_utils.TRAIN_FREQ:])
        reps_final[r].append(differ)
        err_final_differs.append(differ)

    result = {i:0 for i in range(self._n_replicas)}
    for r in range(self._n_replicas):
      result[r] = np.mean(reps[r])
    self._vals['__debug__err_differ'] = result
    
    err_differ = np.mean(err_differs)
    err_differ_std = np.std(err_differs)

    self._vals['avg_err_differ'] = err_differ
    self._vals['avg_err_differ_err'] = err_differ_std
    self._vals['avg_err_final_differ'] = np.mean(err_final_differs)
    self._vals['avg_err_final_differ_err'] = np.std(err_final_differs)

    return sep, err_differ, err_differ_std

  def get_diffusion_vs_min_error(self):
    """Returns a min loss and diffusion value to achieve this min loss."""

    if self._vals['avg_min_error'] is None:
      losses = []
      diffs = []
      steps = []
      replicas = []

      for s in range(self._n_simulations):
        candidate_losses = []
        candidate_diffs = []
        candidate_steps = []

        for r in range(self._n_replicas):
          x_loss, y_loss = self.get_summary('test_error', replica_id=r,
                                            simulation_num=s)
          x_diff, y_diff = self.get_summary('diffusion', replica_id=r,
                                            simulation_num=s)
          y_loss = np.asarray(y_loss)
          loss_idx = y_loss.argmin()
          diff_idx = _find_nearest_idx(x_diff, x_loss[loss_idx])
          candidate_losses.append(y_loss[loss_idx])
          candidate_diffs.append(y_diff[diff_idx])
          candidate_steps.append(x_loss[loss_idx])
        
        self._vals['replica_id_min_err_sim_' + str(s)] = np.argmin(candidate_losses)

        idx = np.argmin(np.asarray(candidate_losses))
        losses.append(candidate_losses[idx])
        diffs.append(candidate_diffs[idx])
        steps.append(candidate_steps[idx])
        replicas.append(idx)

      loss_val = np.mean(losses)
      loss_err = np.std(losses)
      diff_val = np.mean(diffs)
      diff_err = np.std(diffs)
      step_val = np.mean(steps)
      step_err = np.std(steps)

      self._vals['avg_min_error'] = loss_val
      self._vals['avg_min_error_err'] = loss_err
      self._vals['avg_diff_for_min_error'] = diff_val
      self._vals['avg_diff_for_min_error_err'] = diff_err
      self._vals['avg_steps_for_min_error'] = step_val
      self._vals['avg_steps_for_min_error_err'] = step_err

    
    else:
      loss_val = self._vals['avg_min_error']
      loss_err = self._vals['avg_min_error_err']
      diff_val = self._vals['avg_diff_for_min_error']
      diff_err = self._vals['avg_diff_for_min_error_err']
    
    sep = self.get_description()['separation_ratio']
    return diff_val, diff_err, loss_val, loss_err, sep

  def get_n_steps_vs_min_error(self):
    """Returns a min error and number of steps to achieve this min loss."""
    if self._vals['avg_min_error'] is None:
      _ = self.get_diffusion_vs_min_error()

    loss_val = self._vals['avg_min_error']
    loss_err = self._vals['avg_min_error_err']
    step_val = self._vals['avg_steps_for_min_error']
    step_err = self._vals['avg_steps_for_min_error_err']
    sep = self.get_description()['separation_ratio']

    return step_val, step_err, loss_val, loss_err, sep

  def get_sep_ratio_vs_min_error(self):
    if self._vals['avg_min_error'] is None:
      _ = self.get_diffusion_vs_min_error()

    loss_val = self._vals['avg_min_error']
    loss_err = self._vals['avg_min_error_err']
    sep = self.get_description()['separation_ratio']

    return sep, loss_val, loss_err

  def get_sep_ratio_vs_accept_ratio(self):
    """Returns a tuple (`sep_ratio`, `accept_ratio`, `stddev`)."""
    
    sep = self.get_description()['separation_ratio']
    acc = self.get_accept_ratio()
    stddev = self._vals['accept_ratio_err']

    return sep, acc, stddev

  def get_sep_ratio_vs_mix_ratio(self):
    """Returns a tuple (`sep_ratio`, `mix_ratio`, `stddev`)."""
    sep = self.get_description()['separation_ratio']
    mix = self.get_mix_ratio()
    stddev = self._vals['mix_ratio_err']

    return sep, mix, stddev

  def get_sep_ratio_vs_visit_ratio(self):
    """Returns a tuple (`sep_ratio`, `visit_ratio`, `stddev`)."""

    sep = self.get_description()['separation_ratio']
    visit = self.get_visit_ratio()
    stddev = self._vals['visit_ratio_err']

    return sep, visit, stddev

  def show_report(self, simulation_num=0, sample_every=2):
    """Shows the report of the simulation with plots."""
    sep, acc, stddev = self.get_sep_ratio_vs_accept_ratio()
    print('Accept Ratio:', acc, '+/-', stddev)

    sep, visit, stddev = self.get_sep_ratio_vs_visit_ratio()
    print('Visit Ratio:', visit, '+/-', stddev)

    sep, mix, stddev = self.get_sep_ratio_vs_mix_ratio()
    print('Mixing Ratio:', mix, '+/-', stddev)

    sep, loss_val, loss_err = self.get_sep_ratio_vs_min_error()
    print('Min Error value:', loss_val, '+/-', loss_err)

    sep, err_differ, err_differ_std = self.get_sep_ratio_vs_err_differ()
    print('Average Overfitting:',
          err_differ,
          '+/-',
          err_differ_std)
    
    print()
    _ = self._plot_loss(summ_name='test_loss',
                        simulation_num=simulation_num,
                        sample_every=sample_every)
    _ = self._plot_loss(summ_name='train_loss',
                        simulation_num=simulation_num,
                        sample_every=sample_every)
    _ = self._plot_error(summ_name='test_error',
                         simulation_num=simulation_num,
                         sample_every=sample_every)
    _ = self._plot_error(summ_name='train_error',
                         simulation_num=simulation_num,
                         sample_every=sample_every)
    _ = self._plot_diffusion(simulation_num=simulation_num)
    _ = self._plot_mixing(simulation_num=simulation_num)
    '''
    _ = self._plot_grads(simulation_num=simulation_num,
                         sample_every=sample_every)
    _ = self._plot_norms(simulation_num=simulation_num)
    '''
  def get_accept_ratio(self):
    accepts = []
    if self._vals['accept_ratio'] is None:
      for s in range(self._n_simulations):
        for r in range(self._n_replicas):
          x, y = self.get_summary('accepts', replica_id=r, simulation_num=s)
          accepts.append(np.mean(y))
      self._vals['accept_ratio'] = np.mean(accepts)
      self._vals['accept_ratio_err'] = np.std(accepts)

    return self._vals['accept_ratio']

  def get_mix_ratio(self):
    if self._vals['mix_ratio'] is None:
      keys = [float("{0:.4f}".format(b))
              for b in self.get_description()['noise_list']]

      def _get_key(key):
        return keys[int(np.argmin([abs(k-key) for k in keys]))]

      mixing = {i:[] for i in range(self._n_replicas)}
      visiting = {i:[] for i in range(self._n_replicas)}
      travel_times = []
      for s in range(self._n_simulations):

        for r in range(self._n_replicas):
          x, y = self.get_summary('noise_values', replica_id=r, simulation_num=s)
          steps = self.get_summary('train_steps', replica_id=r, simulation_num=s)

          reps = {k:0 for k in keys}

          for i in range(len(steps[1])):
            if steps[1][i] > self.get_description()['burn_in_period']:
              reps[_get_key(y[i])] += 1

          d = dict(replica_id=r,
                   simulation_num=s)
          d.update(reps)
          self._vals['__debug__visit_raw'].append(d)

          visiting[r].append(np.mean([1 if reps[x]!=0 else 0 for x in reps]))
          mixing[r].append(1 if all(reps[x]!=0 for x in reps) else 0)

      mix_ratios = []
      visit_ratios = []

      for s in range(self._n_simulations):
        mix_ratio = np.mean([mixing[r][s] for r in range(self._n_replicas)])
        visit_ratio = np.mean([visiting[r][s] for r in range(self._n_replicas)])
        mix_ratios.append(mix_ratio)
        visit_ratios.append(visit_ratio)
      self._vals['mix_ratio'] = np.mean(mix_ratios)
      self._vals['visit_ratio'] = np.mean(visit_ratios)
      self._vals['mix_ratio_err'] = np.std(mix_ratios)
      self._vals['visit_ratio_err'] = np.std(visit_ratios)

    return self._vals['mix_ratio']

  def get_visit_ratio(self):
    if self._vals['visit_ratio'] is None:
      _ = self.get_mix_ratio()
    return self._vals['visit_ratio']

  def get_summary(self, summ_name, replica_id=0, simulation_num=0):
    """Returns summary for `summ_name`.

    Args:
      `summ_name`: Summary name. For a list of summaries see
        `simulator.graph.summary.flush_summary()` function.
      `replica_id`: A integer representing replica id.
      `simulation_num`: A simulation from which to return the summary.

    Returns:
      A tuple `(x, y)` where `x` is a numpy array of epochs and `y` is
      a list of summary.

    Raises:
      `ValueError`: If `simulation_num` is not in valid range.
    """

    if simulation_num >= self._n_simulations:
      err_msg = ("No such simulation: "
                 + str(simulation_num))
      raise ValueError(err_msg)
    if 'steps' in summ_name:
      y = self._summaries[simulation_num][summ_name]
    else:
      y = self._summaries[simulation_num][summ_name][replica_id]
    n_epochs = self._summaries[simulation_num]['latest_epoch'] + 1
    try:
      x = np.linspace(start=0,
                      stop=n_epochs,
                      num=len(y))
    except TypeError:
      print(summ_name, y)
      raise
    return x, y

  def get_description(self):
    return self._description

  def _plot_norms(self, simulation_num=0):
    fig, ax = plt.subplots()
    plot = Plot()
    for r in range(self._n_replicas):
      x, y = self.get_summary('weight_norms', r, simulation_num)
      plot.plot(x, y, fig=fig, ax=ax, label='replica ' + str(r),
                linewidth=2)
    plot.legend(fig, ax, legend_title='ReplicaID',
                xlabel='EPOCHS', ylabel='WEIGHT L2 NORM')
    return fig

  def _plot_diffusion(self, simulation_num=0):
    fig, ax = plt.subplots()
    plot = Plot()
    for r in range(self._n_replicas):
      x, y = self.get_summary('diffusion', r, simulation_num)
      plot.plot(x, y, fig=fig, ax=ax, label='replica ' + str(r),
                linewidth=2)

    plot.legend(fig, ax, legend_title='ReplicaID',
                xlabel='EPOCHS', ylabel='DIFFUSION')
    return fig

  def _plot_grads(self, simulation_num=0, sample_every=1):
    fig, ax = plt.subplots()
    plot = Plot()
    for r in range(self._n_replicas):
      x, y = self.get_summary('grad_norms', r, simulation_num)
      x, y = x[::sample_every], y[::sample_every]
      plot.plot(x, y, fig=fig, ax=ax, label='replica ' + str(r),
                linewidth=1.5)

    plot.legend(fig, ax, legend_title='ReplicaID',
                xlabel='EPOCHS', ylabel='GRADIENT L2 NORM', log_y=5)

    return fig

  def _plot_loss(self, summ_name,simulation_num=0, sample_every=1):
    fig, ax = plt.subplots()
    plot = Plot()
    for r in range(self._n_replicas):
      if summ_name == 'test_loss':
        x, y = self.get_summary('test_loss', r, simulation_num)
        plot.plot(x, y, fig=fig, ax=ax, label='test_replica_' + str(r),
                  linewidth=1, color=self._colors[r])
      elif summ_name == 'train_loss':
        x1, y1 = self.get_summary('train_loss', r, simulation_num)
        #y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
        y1 = y1[::sample_every]
        x1 = np.linspace(start=0, stop=x1[-1], num=len(y1))
        plot.plot(x1, y1, fig=fig, ax=ax, label='train_replica ' + str(r),
                  linewidth=1, linestyle='--', splined_points_mult=None,
                  color=self._colors[r])

    plot.legend(fig, ax, title=summ_name.upper().replace('_', ' '),
                legend_title='ReplicaID', xlabel='EPOCHS',
                ylabel='LOSS', ylimit=(0, 5))

  def _plot_error(self, summ_name, simulation_num=0, sample_every=1):
    fig, ax = plt.subplots()
    plot = Plot()
    for r in range(self._n_replicas):
      if summ_name == 'test_error':
        x, y = self.get_summary('test_error', r, simulation_num)
        plot.plot(x, y, fig=fig, ax=ax, label='test_replica_' + str(r),
                  linewidth=1, color=self._colors[r])
      elif summ_name == 'train_error':
        x1, y1 = self.get_summary('train_error', r, simulation_num)
        #y1 = [(a + b) / 2 for a, b in zip(y1[::2], y1[1::2])]
        y1 = y1[::sample_every]
        x1 = np.linspace(start=0, stop=x1[-1], num=len(y1))
        plot.plot(x1, y1, fig=fig, ax=ax, label='train_replica ' + str(r),
                  linewidth=1, linestyle='--', splined_points_mult=None,
                  color=self._colors[r])

    plot.legend(fig, ax, legend_title='ReplicaID',
                title=summ_name.upper().replace('_', ' '),
                xlabel='EPOCHS', ylabel='0-1 ERROR', ylimit=(0, 0.8))

  def _plot_mixing(self, simulation_num=0):
    def _get_key(key):
      keys = [float("{0:.5f}".format(b))
              for b in self.get_description()['noise_list']]
      return keys[int(np.argmin([abs(k-key) for k in keys]))]

    fig, ax = plt.subplots()
    plot = Plot()
    noise_list = self.get_description()['noise_list']

    key_map = {_get_key(key):i for i, key in enumerate(noise_list)}
    for r in range(self._n_replicas):
      x, y = self.get_summary('noise_values', replica_id=r, simulation_num=simulation_num)

      y_new = [key_map[_get_key(i)] for i in y]
      plot.plot(x, y_new, fig=fig, ax=ax, label='replica ' + str(r),
                linewidth=2)
    yticks_names = [float("{0:.5f}".format(b)) for b in noise_list]
    #print(yticks_names)
    #print(noise_list)
    plt.gca().set_yticklabels(['0'] + yticks_names)
    plot.legend(fig, ax, legend_title='ReplicaID',
                xlabel='EPOCHS', ylabel='NOISE LEVEL')
    return fig

def _find_nearest_idx(array, value):
  """Returns the index of the closest to the `value` value in `array`."""
  array = np.asarray(array)
  idx = (np.abs(array-value)).argmin()
  return idx