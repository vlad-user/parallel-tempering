{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('/home/deep09/project_vlad/parallel-tempering/')\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from simulator import read_datasets\n",
    "from simulator.simulator import Simulator\n",
    "from simulator.models.cifar10_models_v2 import lenet5_with_dropout\n",
    "#from simulator.models.emnist_models import lenet5_with_lr\n",
    "#from simulator.models.emnist_models import lenet5_with_input_noise\n",
    "#from simulator.models.emnist_models import lenet5 # <-- for regularization or weight_noise\n",
    "#from simulator.models.emnist_models import lenet5_with_const_dropout\n",
    "from simulator import simulator_utils as s_utils\n",
    "import gc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout proba_coeff higher ==> accept higher\n",
    "params = dict(\n",
    "        n_epochs=[251, 251, 2000, 2000, 2000, 2000],\n",
    "        learning_rate=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
    "        n_replicas=[8, 8, 8, 8, 10, 10, 10],\n",
    "        noise_type=['dropout_gd', 'dropout_gd', 'weight_noise', 'weight_noise', 'input_noise', 'l2_regularizer'],\n",
    "        func_name=['lenet5', 'lenet5', 'lenet5', 'lenet5', 'lenet5', 'lenet5', 'lenet5', 'lenet5'],\n",
    "        dataset_name=['cifar', 'cifar', 'emnist', 'emnist', 'emnist', 'emnist'],\n",
    "        loss_func_name=['cross_entropy', 'cross_entropy', 'cross_entropy', 'cross_entropy', 'cross_entropy', 'cross_entropy'],\n",
    "        train_data_size=[45000, 45000, 79920, 79920, 79920, 79920],\n",
    "        model=[lenet5_with_dropout, lenet5_with_dropout, ],\n",
    "        n_simulations=[1, 1, 1, 1, 1, 1],\n",
    "        description=['test', 'test', 'test', 'test', 'test', 'test'],\n",
    "        separation_ratio=[0, 0, 0, 0, 0, 0],\n",
    "        beta_0=[.52, .52, 0.0001, 0.0001, 0.05, 0.01, ],\n",
    "        beta_n=[.65,  0.65, 0.00001, 0.00001, 0.0000001, 0.0000001],\n",
    "        proba_coeff=[10, 0.5, 1, 1, 1, 1, ],\n",
    "        burn_in_period=[12000, np.inf, np.inf, np.inf, np.inf, np.inf],\n",
    "        batch_size=[128, 128, 128, 128, 128, 128],\n",
    "        swap_step=[100, 2000, 2000, 2000, 2000, 2000, 2000,],\n",
    "        mode=[None, None, None, None, None, None]\n",
    "        )\n",
    "\n",
    "test_step = 352\n",
    "n_experiments = 2\n",
    "timer = s_utils.Timer()\n",
    "timer.start_timer()\n",
    "total_sims = np.sum(params['n_simulations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, x_valid, y_valid = read_datasets._create_cifar_data_or_get_existing_lenet5()\n",
    "for i in range(n_experiments):\n",
    "    #if i ==0: continue\n",
    "    simulation_num = 0\n",
    "    noise_list = np.linspace(params['beta_0'][i],\n",
    "                             params['beta_n'][i],\n",
    "                             params['n_replicas'][i]) \n",
    "    noise_list = list(noise_list)\n",
    "    ###############################################\n",
    "\n",
    "    ###############################################\n",
    "    \n",
    "    name = s_utils.generate_experiment_name(model_name=params['func_name'][i],\n",
    "                                            dataset_name=params['dataset_name'][i],\n",
    "                                            separation_ratio=params['separation_ratio'][i],\n",
    "                                            n_replicas=params['n_replicas'][i],\n",
    "                                            beta_0=params['beta_0'][i],\n",
    "                                            beta_n=params['beta_n'][i],\n",
    "                                            loss_func_name=params['loss_func_name'][i],\n",
    "                                            swap_step=params['swap_step'][i],\n",
    "                                            burn_in_period=params['burn_in_period'][i],\n",
    "                                            learning_rate=params['learning_rate'][i],\n",
    "                                            n_epochs=params['n_epochs'][i],\n",
    "                                            noise_type=params['noise_type'][i],\n",
    "                                            batch_size=params['batch_size'][i],\n",
    "                                            proba_coeff=params['proba_coeff'][i],\n",
    "                                            train_data_size=params['train_data_size'][i],\n",
    "                                            mode=params['mode'][i],\n",
    "                                            version='v4')\n",
    "    \n",
    "    \n",
    "    #proba_coeffs = list(np.linspace(100000, 50000, params['n_replicas'][i] -1))\n",
    "    #proba_coeffs = [2000, 5000, 6000, 100000, 100000]\n",
    "    #proba_coeffs = s_utils.generate_proba_coeffs(noise_list, mult=1000)\n",
    "    #print(proba_coeffs)\n",
    "    scheduled_lrs = {1:0.1, 12000:0.01}\n",
    "    \n",
    "    proba_coeffs = params['proba_coeff'][i]\n",
    "    #scheduled_lrs = None\n",
    "    sim = Simulator(model=params['model'][i],\n",
    "                    learning_rate=params['learning_rate'][i],\n",
    "                    noise_list=noise_list,\n",
    "                    noise_type=params['noise_type'][i],\n",
    "                    batch_size=params['batch_size'][i],\n",
    "                    n_epochs=params['n_epochs'][i],\n",
    "                    name=name,\n",
    "                    burn_in_period=params['burn_in_period'][i],\n",
    "                    scheduled_lr=scheduled_lrs,\n",
    "                    swap_step=params['swap_step'][i],\n",
    "                    separation_ratio=params['separation_ratio'][i],\n",
    "                    n_simulations=params['n_simulations'][i],\n",
    "                    test_step=test_step,\n",
    "                    loss_func_name=params['loss_func_name'][i],\n",
    "                    #proba_coeff=params['proba_coeff'][i],\n",
    "                    proba_coeff=proba_coeffs,\n",
    "                    mode=params['mode'][i])\n",
    "    \n",
    "    for sim_num in range(params['n_simulations'][i]):\n",
    "        simulation_num += 1\n",
    "        '''\n",
    "        train_data, train_labels, test_data, test_labels, valid_data, valid_labels = (\n",
    "                                    read_datasets.get_cifar10_data())\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        print(name, str(i) + '/' + str(n_experiments))\n",
    "        \n",
    "        print('train-data-shape: {}'.format(x_train.shape))\n",
    "        print('test-data-shape: {}'.format(x_test.shape))\n",
    "        print('valid-data-shape: {}'.format(x_valid.shape))\n",
    "        print('noise_list:')\n",
    "        print([\"{0:.6f}\".format(n) for n in sorted(noise_list)])\n",
    "        sim.train(train_data_size=None,\n",
    "                  train_data=x_train,\n",
    "                  train_labels=y_train,\n",
    "                  validation_data=x_valid,\n",
    "                  validation_labels=y_valid,\n",
    "                  test_data=x_test,\n",
    "                  test_labels=y_test)\n",
    "        del sim\n",
    "        gc.collect()\n",
    "        print()\n",
    "        print(str(simulation_num) + '/' + str(n_experiments), ', time took:', timer.elapsed_time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
