{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# train a single replica\\nsteps = {'train_step': 176,\\n         'test_step': 352,\\n         'valid_step': 352}\\ntrain_resnet.train(182, steps)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/deep09/project_vlad/parallel-tempering/')\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle as arys_shuffle\n",
    "\n",
    "from simulator.simulator import Simulator\n",
    "from simulator.models.cifar10_models import resnet\n",
    "from simulator import simulator_utils as s_utils\n",
    "'''\n",
    "# train a single replica\n",
    "steps = {'train_step': 176,\n",
    "         'test_step': 352,\n",
    "         'valid_step': 352}\n",
    "train_resnet.train(182, steps)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.005 0.0005\n",
    "# coeff lower ==> accepts higher\n",
    "params = dict(\n",
    "        n_epochs=[182, 182, 182, 182, 182, 182],\n",
    "        learning_rate=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "        n_replicas=[6, 8, 8, 6, 8, 8],\n",
    "        noise_type=['learning_rate_momentum', 'learning_rate_momentum', 'learning_rate_momentum', 'learning_rate_momentum', 'learning_rate_momentum', 'learning_rate_momentum'],\n",
    "        func_name=['resnet20', 'resnet32', 'resnet44', 'resnet20', 'resnet32', 'resnet44'],\n",
    "        dataset_name=['cifar', 'cifar', 'cifar', 'cifar', 'cifar', 'cifar'],\n",
    "        loss_func_name=['cross_entropy', 'cross_entropy', 'cross_entropy', 'cross_entropy', 'cross_entropy', 'cross_entropy'],\n",
    "        train_data_size=[45000, 45000, 45000, 45000, 45000, 45000],\n",
    "        model=[None, None, None, None, None, None],\n",
    "        n_simulations=[1, 1, 1, 1, 1, 1],\n",
    "        description=['test', 'test', 'test', 'test', 'test', 'test'],\n",
    "        separation_ratio=[0, 0, 0, 0, 0, 0],\n",
    "        beta_0=[0.05, 0.02, 0.02, 0.05, 0.03, 0.02, ],\n",
    "        beta_n=[0.005,  0.0005, 0.0001, 0.005,  0.001, 0.0001,],\n",
    "        proba_coeff=[0.1, 0.02, 0.005, 0.1, 0.02, 0.005,],\n",
    "        burn_in_period=[32000, 32000, 32000, 32000, 32000, 32000, ],\n",
    "        batch_size=[128, 128, 128, 128, 128, 128],\n",
    "        swap_step=[200, 200, 200, 200, 200, 200],\n",
    "        mode=[None, None, None, None, None, None],\n",
    "        scheduled_noise=[True, True, True, True, True, True],\n",
    "        resnet_size=[20, 32, 44, 20, 32, 44])\n",
    "\n",
    "test_step = 352\n",
    "n_experiments = 6\n",
    "timer = s_utils.Timer()\n",
    "timer.start_timer()\n",
    "total_sims = np.sum(params['n_simulations'])\n",
    "\n",
    "assert all(len(v) >= n_experiments for k, v in params.items())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/deep09/project_vlad/parallel-tempering/simulator/models/resnet/resnet_v2.py:33: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0520 00:01:44.900784 140150092326656 tf_logging.py:125] From /home/deep09/project_vlad/parallel-tempering/simulator/models/resnet/resnet_v2.py:33: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet20_cifar_0_45000_6_0.05_crossentropy_200_32000_0.1_182_128_learningratemomentum_0.1_0.005_None_v3 1/6\n",
      "train-data-shape: (45000, 32, 32, 3)\n",
      "[epoch:181]|[step:64065]|[0.100, 0.095, 0.096, 0.098, 0.102, 0.105]|[accept:0.931]\n",
      "1/6 , time took: 161\n",
      "resnet32_cifar_0_45000_8_0.03_crossentropy_200_32000_0.1_182_128_learningratemomentum_0.08_0.001_None_v3 1/6\n",
      "train-data-shape: (45000, 32, 32, 3)\n",
      "[epoch:181]|[step:64065]|[0.090, 0.089, 0.088, 0.093, 0.093, 0.089, 0.090, 0.092]|[accept:0.875]\n",
      "1/6 , time took: 321\n",
      "resnet44_cifar_0_45000_8_0.02_crossentropy_200_32000_0.1_182_128_learningratemomentum_0.06_0.0005_None_v3 1/6\n",
      "train-data-shape: (45000, 32, 32, 3)\n",
      "[epoch:164]|[step:57998]|[0.086, 0.089, 0.086, 0.082, 0.087, 0.085, 0.083, 0.087]|[accept:0.891]"
     ]
    }
   ],
   "source": [
    "from simulator.read_datasets import _create_cifar_data_or_get_existing_resnet\n",
    "x_train, y_train, x_test, y_test, x_valid, y_valid = (\n",
    "        _create_cifar_data_or_get_existing_resnet())\n",
    "\n",
    "for i in range(n_experiments):\n",
    "    #if i <= 2: continue\n",
    "    simulation_num = 0\n",
    "\n",
    "\n",
    "\n",
    "    noise_list = list(np.linspace(params['beta_0'][i], params['beta_n'][i], params['n_replicas'][i]))\n",
    "    if params['scheduled_noise'][i]:\n",
    "        scheduled_noise = {32000: noise_list,\n",
    "                           1: [0.1 for _ in range(params['n_replicas'][i])]}\n",
    "    #noise_list = [0.018, 0.22]\n",
    "    name = s_utils.generate_experiment_name(model_name=params['func_name'][i],\n",
    "                                            dataset_name=params['dataset_name'][i],\n",
    "                                            separation_ratio=params['separation_ratio'][i],\n",
    "                                            n_replicas=params['n_replicas'][i],\n",
    "                                            beta_0=params['beta_0'][i],\n",
    "                                            beta_n=params['beta_n'][i],\n",
    "                                            loss_func_name=params['loss_func_name'][i],\n",
    "                                            swap_step=params['swap_step'][i],\n",
    "                                            burn_in_period=params['burn_in_period'][i],\n",
    "                                            learning_rate=params['learning_rate'][i],\n",
    "                                            n_epochs=params['n_epochs'][i],\n",
    "                                            noise_type=params['noise_type'][i],\n",
    "                                            batch_size=params['batch_size'][i],\n",
    "                                            proba_coeff=params['proba_coeff'][i],\n",
    "                                            train_data_size=params['train_data_size'][i],\n",
    "                                            mode=params['mode'][i])\n",
    "    ensembles = resnet(tf.Graph(), params['n_replicas'][i], params['resnet_size'][i])\n",
    "    sim = Simulator(model=params['model'][i],\n",
    "                    learning_rate=params['learning_rate'][i],\n",
    "                    noise_list=noise_list,\n",
    "                    noise_type=params['noise_type'][i],\n",
    "                    batch_size=params['batch_size'][i],\n",
    "                    n_epochs=params['n_epochs'][i],\n",
    "                    name=name,\n",
    "                    ensembles=ensembles,\n",
    "                    burn_in_period=params['burn_in_period'][i],\n",
    "                    swap_step=params['swap_step'][i],\n",
    "                    separation_ratio=params['separation_ratio'][i],\n",
    "                    n_simulations=params['n_simulations'][i],\n",
    "                    scheduled_noise=scheduled_noise,\n",
    "                    test_step=test_step,\n",
    "                    loss_func_name=params['loss_func_name'][i],\n",
    "                    proba_coeff=params['proba_coeff'][i],\n",
    "                    mode=params['mode'][i])\n",
    "    \n",
    "    for sim_num in range(params['n_simulations'][i]):\n",
    "        simulation_num += 1\n",
    "        '''\n",
    "        train_data, train_labels, test_data, test_labels, valid_data, valid_labels = (\n",
    "                                    read_datasets.get_cifar10_data())\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        print(name, str(simulation_num) + '/' + str(total_sims))\n",
    "        print('train-data-shape: {}'.format(x_train.shape))\n",
    "        sim.train(train_data_size=45000,\n",
    "                  train_data=x_train,\n",
    "                  train_labels=y_train,\n",
    "                  validation_data=x_valid,\n",
    "                  validation_labels=y_valid,\n",
    "                  test_data=x_test,\n",
    "                  test_labels=y_test)\n",
    "        del sim\n",
    "        del ensembles\n",
    "        gc.collect()\n",
    "        print()\n",
    "        print(str(simulation_num) + '/' + str(n_experiments), ', time took:', timer.elapsed_time())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
